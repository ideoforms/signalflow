{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"SignalFlow Warning This documentation is a work-in-progress and may have sections that are missing or incomplete. SignalFlow is an audio DSP framework whose goal is to make it quick and intuitive to explore complex sonic ideas. It has a simple and consistent Python API, allowing for rapid prototyping in Jupyter, PyCharm, or on the command-line. It comes with over 100 of built-in node classes for creative exploration. Its core is implemented in C++11, with cross-platform hardware acceleration. SignalFlow has robust support for macOS and Linux (including Raspberry Pi), and has work-in-progress support for Windows. The overall project is currently in alpha status, and interfaces may change without warning. This documentation currently focuses specifically on Python interfaces and examples. Overview At its core, SignalFlow has a handful of key concepts. At the top level is the AudioGraph , which connects to the system's audio input/output hardware. The graph comprises of a network of Nodes , each of which performs a single function (for example, generating a cyclical waveform, or filtering an input node). Nodes are connected by input and output relationships: the output of one node may be used to control the frequency of another. As the output of the first node increases, the frequency of the second node increases correspondingly. This modulation is applied on a sample-by-sample basis: all modulation in SignalFlow happens at audio rate. Nodes may have multiple inputs , which determine which synthesis properties can be modulated at runtime. A node can also have Buffer properties, which contain audio waveform data that can be read and written to, for playback or recording of samples. Nodes can be grouped in a Patch , which is a user-defined configuration of nodes. A patch may have one or more named inputs that are defined by the user when creating the patch. Patches can be thought of like voices of a synthesizer. A patch can also be set to automatically remove itself from the graph when a specified node's playback is complete, which is important for automatic memory management. Example Let's take a look at a minimal SignalFlow example. Here, we create and immediately start the AudioGraph , construct a stereo sine oscillator, connect the oscillator to the graph's output, and run the graph indefinitely. from signalflow import * graph = AudioGraph () sine = SineOscillator ([ 440 , 880 ]) envelope = ASREnvelope ( 0.1 , 0.1 , 0.5 ) output = sine * envelope output . play () graph . wait () This demo shows a few syntactical benefits that SignalFlow provides to make it easy to work with audio: The 2-item array of frequency values passed to SineOscillator is expanded to create a stereo, 2-channel output. If you passed a 10-item array, the output would have 10 channels. Mathematical operators like * can be used to multiply, add, subtract or divide the output of nodes, and creates a new output Node that corresponds to the output of the operation. This example uses an envelope to modulate the amplitude of an oscillator. Even through the envelope is mono and the oscillator is stereo, SignalFlow does the right thing and upmixes the envelope's values to create a stereo output, so that the same envelope shape is applied to the L and R channels of the oscillator, before creating a stereo output. This is called \"automatic upmixing\", and is handy when working with multichannel graphs. In subsequent examples, we will skip the import line and assume you have already imported everything from the signalflow namespace. Info If you want to keep your namespaces better separated, you might want to do something like the below. import signalflow as sf graph = sf . AudioGraph () sine = sf . SineOscillator ( 440 ) ... Documentation Getting started Example code","title":"Home"},{"location":"#signalflow","text":"Warning This documentation is a work-in-progress and may have sections that are missing or incomplete. SignalFlow is an audio DSP framework whose goal is to make it quick and intuitive to explore complex sonic ideas. It has a simple and consistent Python API, allowing for rapid prototyping in Jupyter, PyCharm, or on the command-line. It comes with over 100 of built-in node classes for creative exploration. Its core is implemented in C++11, with cross-platform hardware acceleration. SignalFlow has robust support for macOS and Linux (including Raspberry Pi), and has work-in-progress support for Windows. The overall project is currently in alpha status, and interfaces may change without warning. This documentation currently focuses specifically on Python interfaces and examples.","title":"SignalFlow"},{"location":"#overview","text":"At its core, SignalFlow has a handful of key concepts. At the top level is the AudioGraph , which connects to the system's audio input/output hardware. The graph comprises of a network of Nodes , each of which performs a single function (for example, generating a cyclical waveform, or filtering an input node). Nodes are connected by input and output relationships: the output of one node may be used to control the frequency of another. As the output of the first node increases, the frequency of the second node increases correspondingly. This modulation is applied on a sample-by-sample basis: all modulation in SignalFlow happens at audio rate. Nodes may have multiple inputs , which determine which synthesis properties can be modulated at runtime. A node can also have Buffer properties, which contain audio waveform data that can be read and written to, for playback or recording of samples. Nodes can be grouped in a Patch , which is a user-defined configuration of nodes. A patch may have one or more named inputs that are defined by the user when creating the patch. Patches can be thought of like voices of a synthesizer. A patch can also be set to automatically remove itself from the graph when a specified node's playback is complete, which is important for automatic memory management.","title":"Overview"},{"location":"#example","text":"Let's take a look at a minimal SignalFlow example. Here, we create and immediately start the AudioGraph , construct a stereo sine oscillator, connect the oscillator to the graph's output, and run the graph indefinitely. from signalflow import * graph = AudioGraph () sine = SineOscillator ([ 440 , 880 ]) envelope = ASREnvelope ( 0.1 , 0.1 , 0.5 ) output = sine * envelope output . play () graph . wait () This demo shows a few syntactical benefits that SignalFlow provides to make it easy to work with audio: The 2-item array of frequency values passed to SineOscillator is expanded to create a stereo, 2-channel output. If you passed a 10-item array, the output would have 10 channels. Mathematical operators like * can be used to multiply, add, subtract or divide the output of nodes, and creates a new output Node that corresponds to the output of the operation. This example uses an envelope to modulate the amplitude of an oscillator. Even through the envelope is mono and the oscillator is stereo, SignalFlow does the right thing and upmixes the envelope's values to create a stereo output, so that the same envelope shape is applied to the L and R channels of the oscillator, before creating a stereo output. This is called \"automatic upmixing\", and is handy when working with multichannel graphs. In subsequent examples, we will skip the import line and assume you have already imported everything from the signalflow namespace. Info If you want to keep your namespaces better separated, you might want to do something like the below. import signalflow as sf graph = sf . AudioGraph () sine = sf . SineOscillator ( 440 ) ...","title":"Example"},{"location":"#documentation","text":"Getting started Example code","title":"Documentation"},{"location":"examples/","text":"Examples For various code examples using SignalFlow, see examples/python in GitHub: https://github.com/ideoforms/signalflow/tree/master/examples/python","title":"Examples"},{"location":"examples/#examples","text":"For various code examples using SignalFlow, see examples/python in GitHub: https://github.com/ideoforms/signalflow/tree/master/examples/python","title":"Examples"},{"location":"getting-started/","text":"Getting started Installation SignalFlow is not yet available for installation via pip. You will currently need to clone the GitHub repo and build and run from the command line, which is hopefully a quick and easy process. For details, see the README in the repo: https://github.com/ideoforms/signalflow Examples Several example scripts are included within the repo, covering simple control and modulation, FM synthesis, sample granulation, MIDI control, chaotic functions, etc.","title":"Getting started"},{"location":"getting-started/#getting-started","text":"","title":"Getting started"},{"location":"getting-started/#installation","text":"SignalFlow is not yet available for installation via pip. You will currently need to clone the GitHub repo and build and run from the command line, which is hopefully a quick and easy process. For details, see the README in the repo: https://github.com/ideoforms/signalflow","title":"Installation"},{"location":"getting-started/#examples","text":"Several example scripts are included within the repo, covering simple control and modulation, FM synthesis, sample granulation, MIDI control, chaotic functions, etc.","title":"Examples"},{"location":"license/","text":"License SignalFlow is under the MIT license . This means that you are welcome to use it for any purpose, including commercial usage, but must include the copyright notice above in any copies or derivative works. Please do let me know what you use it for!","title":"License"},{"location":"license/#license","text":"SignalFlow is under the MIT license . This means that you are welcome to use it for any purpose, including commercial usage, but must include the copyright notice above in any copies or derivative works. Please do let me know what you use it for!","title":"License"},{"location":"_isobar/","text":"isobar isobar is a Python library for creating and manipulating musical patterns, designed for use in algorithmic composition, generative music and sonification. It makes it quick and easy to express complex musical ideas, and can send and receive events from various different sources: MIDI, OSC, SocketIO, and .mid files. What isobar does The core objective of isobar is to provide a framework for sequencing and triggering events, which may be MIDI messages, OSC triggers, triggers for third-party DSP engines such as SuperCollider, or even Python functions. ( What types of event are supported? ) It can be used to trigger events in real time, or to generate patterns that can be serialised as MIDI files and loaded into a DAW. It can sync to external clocks, or act as a clock source to external devices. It can also load patterns serialised in MIDI files for processing. What isobar doesn't do isobar does not generate any audio on its own. It must be configured to send events to an output device which is responsible for sound synthesis. Basic concepts There are a few key components in isobar. The Timeline handles timing and scheduling, triggering events at the correct moment. It is made up of multiple Tracks, which normally . It can maintain its own clock with millisecond accuracy, or sync to an external clock. Events correspond to triggers that are typically sent to output devices or received from input devices. These may be MIDI notes, control changes, OSC triggers, and other general types. An event is typically described by a dict with a number of properties. For example: { \"note\" : 60, \"amplitude\": 127 } Patterns : Each of the properties of an event can be specified by a Pattern, which generates a sequence of return values. Simple pattern types generate fixed sequences, random values, or values based on statistical models. Patterns can be passed other patterns as parameters, so they can operate on each other -- for example, causing an input pattern to loop N times, or skipping the input values with some probability. Devices : Events are sent to output devices, over interfaces such as MIDI or OSC. Events can also be received and processed. Flow diagram Documentation Getting started Code examples Pattern library reference","title":"isobar"},{"location":"_isobar/#isobar","text":"isobar is a Python library for creating and manipulating musical patterns, designed for use in algorithmic composition, generative music and sonification. It makes it quick and easy to express complex musical ideas, and can send and receive events from various different sources: MIDI, OSC, SocketIO, and .mid files.","title":"isobar"},{"location":"_isobar/#what-isobar-does","text":"The core objective of isobar is to provide a framework for sequencing and triggering events, which may be MIDI messages, OSC triggers, triggers for third-party DSP engines such as SuperCollider, or even Python functions. ( What types of event are supported? ) It can be used to trigger events in real time, or to generate patterns that can be serialised as MIDI files and loaded into a DAW. It can sync to external clocks, or act as a clock source to external devices. It can also load patterns serialised in MIDI files for processing.","title":"What isobar does"},{"location":"_isobar/#what-isobar-doesnt-do","text":"isobar does not generate any audio on its own. It must be configured to send events to an output device which is responsible for sound synthesis.","title":"What isobar doesn't do"},{"location":"_isobar/#basic-concepts","text":"There are a few key components in isobar. The Timeline handles timing and scheduling, triggering events at the correct moment. It is made up of multiple Tracks, which normally . It can maintain its own clock with millisecond accuracy, or sync to an external clock. Events correspond to triggers that are typically sent to output devices or received from input devices. These may be MIDI notes, control changes, OSC triggers, and other general types. An event is typically described by a dict with a number of properties. For example: { \"note\" : 60, \"amplitude\": 127 } Patterns : Each of the properties of an event can be specified by a Pattern, which generates a sequence of return values. Simple pattern types generate fixed sequences, random values, or values based on statistical models. Patterns can be passed other patterns as parameters, so they can operate on each other -- for example, causing an input pattern to loop N times, or skipping the input values with some probability. Devices : Events are sent to output devices, over interfaces such as MIDI or OSC. Events can also be received and processed.","title":"Basic concepts"},{"location":"_isobar/#flow-diagram","text":"","title":"Flow diagram"},{"location":"_isobar/#documentation","text":"Getting started Code examples Pattern library reference","title":"Documentation"},{"location":"_isobar/about/","text":"About the project isobar was first designed for the generative sound installation Variable 4 , in which it was used to generate musical structures in response to changing weather conditions. It was more recently used in The Listening Machine , taking live input from Twitter and generating musical output from language patterns, streamed live over the internet. Many of the concepts behind Pattern and its subclasses are inspired by the brilliant pattern library of the SuperCollider synthesis language.","title":"About the project"},{"location":"_isobar/about/#about-the-project","text":"isobar was first designed for the generative sound installation Variable 4 , in which it was used to generate musical structures in response to changing weather conditions. It was more recently used in The Listening Machine , taking live input from Twitter and generating musical output from language patterns, streamed live over the internet. Many of the concepts behind Pattern and its subclasses are inspired by the brilliant pattern library of the SuperCollider synthesis language.","title":"About the project"},{"location":"_isobar/contributing/","text":"Contributing Third-party contributions are welcomed. Please read the CONTRIBUTING.md , and submit a pull request on GitHub .","title":"Contributing"},{"location":"_isobar/contributing/#contributing","text":"Third-party contributions are welcomed. Please read the CONTRIBUTING.md , and submit a pull request on GitHub .","title":"Contributing"},{"location":"_isobar/example/","text":"isobar isobar is a Python library for creating and manipulating musical patterns, designed for use in algorithmic composition, generative music and sonification. It makes it quick and easy to express complex musical ideas, and can send and receive events from various different sources: MIDI, OSC, SocketIO, and .mid files. Documentation index.md # The documentation homepage. ... # Other markdown pages, images and other files. Installation in a virtual environment The best way to make sure that you end up with the correct versions and without any incompatibility problems between packages it to use a virtual environment . Don't know what this is or how to set it up? We recommend to start by reading a [tutorial on virtual environments][6] for Python. Installation on macOS When you're running the pre-installed version of Python on macOS, pip tries to install packages in a folder for which your user might not have the adequate permissions. There are two possible solutions for this: Unix docker run --rm -it -p 8000:8000 -v ${PWD}:/docs squidfunk/mkdocs-material Windows docker run --rm -it -p 8000:8000 -v \"%cd%\":/docs squidfunk/mkdocs-material","title":"isobar"},{"location":"_isobar/example/#isobar","text":"isobar is a Python library for creating and manipulating musical patterns, designed for use in algorithmic composition, generative music and sonification. It makes it quick and easy to express complex musical ideas, and can send and receive events from various different sources: MIDI, OSC, SocketIO, and .mid files.","title":"isobar"},{"location":"_isobar/example/#documentation","text":"index.md # The documentation homepage. ... # Other markdown pages, images and other files. Installation in a virtual environment The best way to make sure that you end up with the correct versions and without any incompatibility problems between packages it to use a virtual environment . Don't know what this is or how to set it up? We recommend to start by reading a [tutorial on virtual environments][6] for Python. Installation on macOS When you're running the pre-installed version of Python on macOS, pip tries to install packages in a folder for which your user might not have the adequate permissions. There are two possible solutions for this: Unix docker run --rm -it -p 8000:8000 -v ${PWD}:/docs squidfunk/mkdocs-material Windows docker run --rm -it -p 8000:8000 -v \"%cd%\":/docs squidfunk/mkdocs-material","title":"Documentation"},{"location":"_isobar/examples/","text":"Examples A complete set of example scripts are included with isobar, demonstrating applications from simple sequencing functionality to more complex tasks such as clock sync, file I/O, etc. Examples Alternatively, to see how every function across the codebase can be used, browse the unit tests .","title":"Examples"},{"location":"_isobar/examples/#examples","text":"A complete set of example scripts are included with isobar, demonstrating applications from simple sequencing functionality to more complex tasks such as clock sync, file I/O, etc. Examples Alternatively, to see how every function across the codebase can be used, browse the unit tests .","title":"Examples"},{"location":"_isobar/getting-started/","text":"Getting started Requirements isobar has been tested on Linux (Ubuntu, Raspberry Pi OS) and macOS. It has not been officially tested on Windows, although third-party contributions of support and QA efforts would be welcomed. It requires Python 3.5 or above. On Linux, the libasound and libjack-dev packages are also required: apt install libasound2-dev libjack-dev 1. Install isobar The simplest way to install isobar is via pip : pip3 install isobar To download the examples, you will need to clone the repo and install from source: git clone https : // github . com / ideoforms / isobar . git cd isobar pip3 install . 2. Set up an output device The example scripts are based on sending MIDI to a DAW or MIDI-compatible hardware instrument. By default, isobar uses the system's default MIDI output as its output device. If you want to specify a non-standard MIDI output, you can specify it using an environmental variable: export ISOBAR_DEFAULT_MIDI_OUT = \"Prophet 6\" When you run an example script, you can confirm that it is using the right output as it will print the name of the output device it is using. 3. Run an example Inside the repo directory you cloned above, there are a number of example scripts. To run the \"hello world\" example: python3 examples / 00. ex - hello - world . py The script will print the default MIDI driver to screen, and begin triggering notes. Troubleshooting If you don't hear any notes, check that: the name of the correct device is printed to the console your device is configured to listen for MIDI on channel 1, and can play the note 60 Use a MIDI monitor utility to check that the events are registering correctly. Next steps Code examples Read about Patterns , Timelines , Events and Devices ,","title":"Getting started"},{"location":"_isobar/getting-started/#getting-started","text":"","title":"Getting started"},{"location":"_isobar/getting-started/#requirements","text":"isobar has been tested on Linux (Ubuntu, Raspberry Pi OS) and macOS. It has not been officially tested on Windows, although third-party contributions of support and QA efforts would be welcomed. It requires Python 3.5 or above. On Linux, the libasound and libjack-dev packages are also required: apt install libasound2-dev libjack-dev","title":"Requirements"},{"location":"_isobar/getting-started/#1-install-isobar","text":"The simplest way to install isobar is via pip : pip3 install isobar To download the examples, you will need to clone the repo and install from source: git clone https : // github . com / ideoforms / isobar . git cd isobar pip3 install .","title":"1. Install isobar"},{"location":"_isobar/getting-started/#2-set-up-an-output-device","text":"The example scripts are based on sending MIDI to a DAW or MIDI-compatible hardware instrument. By default, isobar uses the system's default MIDI output as its output device. If you want to specify a non-standard MIDI output, you can specify it using an environmental variable: export ISOBAR_DEFAULT_MIDI_OUT = \"Prophet 6\" When you run an example script, you can confirm that it is using the right output as it will print the name of the output device it is using.","title":"2. Set up an output device"},{"location":"_isobar/getting-started/#3-run-an-example","text":"Inside the repo directory you cloned above, there are a number of example scripts. To run the \"hello world\" example: python3 examples / 00. ex - hello - world . py The script will print the default MIDI driver to screen, and begin triggering notes. Troubleshooting If you don't hear any notes, check that: the name of the correct device is printed to the console your device is configured to listen for MIDI on channel 1, and can play the note 60 Use a MIDI monitor utility to check that the events are registering correctly.","title":"3. Run an example"},{"location":"_isobar/getting-started/#next-steps","text":"Code examples Read about Patterns , Timelines , Events and Devices ,","title":"Next steps"},{"location":"_isobar/license/","text":"License isobar is under the MIT license . This means that you are welcome to use it for any purpose, including commercial usage, but must include the copyright notice above in any copies or derivative works. Please do let me know what you use it for!","title":"License"},{"location":"_isobar/license/#license","text":"isobar is under the MIT license . This means that you are welcome to use it for any purpose, including commercial usage, but must include the copyright notice above in any copies or derivative works. Please do let me know what you use it for!","title":"License"},{"location":"_isobar/source-code/","text":"Source code The source code for isobar is hosted on GitHub: github.com/ideoforms/isobar To clone the latest version: git clone https://github.com/ideoforms/isobar.git","title":"Source code"},{"location":"_isobar/source-code/#source-code","text":"The source code for isobar is hosted on GitHub: github.com/ideoforms/isobar To clone the latest version: git clone https://github.com/ideoforms/isobar.git","title":"Source code"},{"location":"_isobar/devices/","text":"Devices and I/O MIDI MIDI file OpenSoundControl","title":"Devices and I/O"},{"location":"_isobar/devices/#devices-and-io","text":"MIDI MIDI file OpenSoundControl","title":"Devices and I/O"},{"location":"_isobar/devices/midi/","text":"MIDI isobar's MIDI support is based on the excellent mido library. Two classes are available for MIDI I/O: MidiOutputDevice Sends note and control events to a MIDI device. isobar can also act as the clock out, so that external MIDI devices follow isobar's internal clock. Virtual MIDI devices To control a MIDI device on the same computer that is running isobar, you will need to create a virtual MIDI bus . name = \"My MIDI Device Name\" midi_out = iso . MidiOutputDevice ( device_name = name , send_clock = True ) timeline = Timeline ( tempo = 120 , output_device = midi_out ) device_name : Specifies the device name to search for. Leave empty to use the system default. send_clock : If True, sends clock sync signals to the external device. A default MIDI output device name can be set with an environmental variable: export ISOBAR_DEFAULT_MIDI_OUT=\"Prophet 6\" MidiInputDevice Receives notes and control events from a MIDI device, or sync isobar to an external MIDI clock. # Receive MIDI messages from an external device name = \"My MIDI Device Name\" midi_in = iso . MidiInputDevice ( device_name = name ) # Blocking mode: waits until a message is received message = midi_in . receive () # Non-blocking: if a message is available, return it; otherwise, return None message = midi_in . poll () # Sync a Timeline to a MIDI external clock name = \"My MIDI Device Name\" midi_in = iso . MidiInputDevice ( device_name = name ) timeline = Timeline ( tempo = 120 , clock_source = midi_in ) A default MIDI input device name can be set with an environmental variable: export ISOBAR_DEFAULT_MIDI_IN=\"Prophet 6\"","title":"MIDI"},{"location":"_isobar/devices/midi/#midi","text":"isobar's MIDI support is based on the excellent mido library. Two classes are available for MIDI I/O:","title":"MIDI"},{"location":"_isobar/devices/midi/#midioutputdevice","text":"Sends note and control events to a MIDI device. isobar can also act as the clock out, so that external MIDI devices follow isobar's internal clock. Virtual MIDI devices To control a MIDI device on the same computer that is running isobar, you will need to create a virtual MIDI bus . name = \"My MIDI Device Name\" midi_out = iso . MidiOutputDevice ( device_name = name , send_clock = True ) timeline = Timeline ( tempo = 120 , output_device = midi_out ) device_name : Specifies the device name to search for. Leave empty to use the system default. send_clock : If True, sends clock sync signals to the external device. A default MIDI output device name can be set with an environmental variable: export ISOBAR_DEFAULT_MIDI_OUT=\"Prophet 6\"","title":"MidiOutputDevice"},{"location":"_isobar/devices/midi/#midiinputdevice","text":"Receives notes and control events from a MIDI device, or sync isobar to an external MIDI clock. # Receive MIDI messages from an external device name = \"My MIDI Device Name\" midi_in = iso . MidiInputDevice ( device_name = name ) # Blocking mode: waits until a message is received message = midi_in . receive () # Non-blocking: if a message is available, return it; otherwise, return None message = midi_in . poll () # Sync a Timeline to a MIDI external clock name = \"My MIDI Device Name\" midi_in = iso . MidiInputDevice ( device_name = name ) timeline = Timeline ( tempo = 120 , clock_source = midi_in ) A default MIDI input device name can be set with an environmental variable: export ISOBAR_DEFAULT_MIDI_IN=\"Prophet 6\"","title":"MidiInputDevice"},{"location":"_isobar/devices/midifile/","text":"MIDI file MidiFileOutputDevice Writing MIDI files is done by setting the output device of a Timeline to a MidiFileOutputDevice isobar normally generates events in real-time according to the tempo of the Timeline. To batch process events instantaneously, set the tempo of the timeline to iso.MAX_CLOCK_RATE . filename = \"output.mid\" output = MidiFileOutputDevice(filename) timeline = iso.Timeline(iso.MAX_CLOCK_RATE, output_device=output) timeline.stop_when_done = True timeline.schedule({ \"note\": iso.PSequence([ 60, 62, 64, 65 ], 1) }) timeline.run() output.write() MidiFileInputDevice Reading MIDI files is done with a MidiFileInputDevice . The method MidiFileInputDevice.read() returns a PDict containing PSequence patterns for each of the MIDI event properties (note, amplitude, duration), which can be scheduled for playback within a timeline: pattern = MidiFileInputDevice ( args . filename ) . read () timeline = iso . Timeline () timeline . schedule ( pattern ) timeline . run () To discard the amplitudes and durations, and make use of just the pitch values: pattern = MidiFileInputDevice ( args . filename ) . read () timeline = iso . Timeline () timeline . schedule ({ \"note\" : pattern [ \"note\" ], \"duration\" : 0.1 }) timeline . run ()","title":"MIDI file"},{"location":"_isobar/devices/midifile/#midi-file","text":"","title":"MIDI file"},{"location":"_isobar/devices/midifile/#midifileoutputdevice","text":"Writing MIDI files is done by setting the output device of a Timeline to a MidiFileOutputDevice isobar normally generates events in real-time according to the tempo of the Timeline. To batch process events instantaneously, set the tempo of the timeline to iso.MAX_CLOCK_RATE . filename = \"output.mid\" output = MidiFileOutputDevice(filename) timeline = iso.Timeline(iso.MAX_CLOCK_RATE, output_device=output) timeline.stop_when_done = True timeline.schedule({ \"note\": iso.PSequence([ 60, 62, 64, 65 ], 1) }) timeline.run() output.write()","title":"MidiFileOutputDevice"},{"location":"_isobar/devices/midifile/#midifileinputdevice","text":"Reading MIDI files is done with a MidiFileInputDevice . The method MidiFileInputDevice.read() returns a PDict containing PSequence patterns for each of the MIDI event properties (note, amplitude, duration), which can be scheduled for playback within a timeline: pattern = MidiFileInputDevice ( args . filename ) . read () timeline = iso . Timeline () timeline . schedule ( pattern ) timeline . run () To discard the amplitudes and durations, and make use of just the pitch values: pattern = MidiFileInputDevice ( args . filename ) . read () timeline = iso . Timeline () timeline . schedule ({ \"note\" : pattern [ \"note\" ], \"duration\" : 0.1 }) timeline . run ()","title":"MidiFileInputDevice"},{"location":"_isobar/devices/osc/","text":"OpenSoundControl To send a sequence of events to an OSC device: osc_device = iso . OSCOutputDevice ( \"127.0.0.1\" , 8010 ) timeline = iso . Timeline ( 120 , output_device = osc_device ) timeline . schedule ({ \"osc_address\" : \"/freq\" , \"osc_params\" : [ iso . PSequence ([ 440 , 880 ]) ] }) Control-rate interpolation is not yet supported for OSC.","title":"OpenSoundControl"},{"location":"_isobar/devices/osc/#opensoundcontrol","text":"To send a sequence of events to an OSC device: osc_device = iso . OSCOutputDevice ( \"127.0.0.1\" , 8010 ) timeline = iso . Timeline ( 120 , output_device = osc_device ) timeline . schedule ({ \"osc_address\" : \"/freq\" , \"osc_params\" : [ iso . PSequence ([ 440 , 880 ]) ] }) Control-rate interpolation is not yet supported for OSC.","title":"OpenSoundControl"},{"location":"_isobar/devices/signalflow/","text":"SignalFlow","title":"SignalFlow"},{"location":"_isobar/devices/signalflow/#signalflow","text":"","title":"SignalFlow"},{"location":"_isobar/devices/supercollider/","text":"SuperCollider","title":"SuperCollider"},{"location":"_isobar/devices/supercollider/#supercollider","text":"","title":"SuperCollider"},{"location":"_isobar/events/","text":"Events Events are scheduled by passing a dict to Timeline.schedule() , which inspects the keys to figure out what type of event you are intending. Event dicts with a note or degree key are assumed to be note events Event dicts with a control or program_change key are assumed to be control events Event dicts with an action key is assumed to be an action event The default values for unspecified parameters in an Event dict are infinite patterns generated by PConstant . This means that, unless a finite parameter is explicitly passed, events will continue to be generated forever. Event types Note events trigger discrete MIDI notes, with a duration and amplitude Control events include MIDI control change, program change and pitchwheel messages, and can apply quasi-continuous control curves Action events call arbitrary Python functions","title":"Events"},{"location":"_isobar/events/#events","text":"Events are scheduled by passing a dict to Timeline.schedule() , which inspects the keys to figure out what type of event you are intending. Event dicts with a note or degree key are assumed to be note events Event dicts with a control or program_change key are assumed to be control events Event dicts with an action key is assumed to be an action event The default values for unspecified parameters in an Event dict are infinite patterns generated by PConstant . This means that, unless a finite parameter is explicitly passed, events will continue to be generated forever.","title":"Events"},{"location":"_isobar/events/#event-types","text":"Note events trigger discrete MIDI notes, with a duration and amplitude Control events include MIDI control change, program change and pitchwheel messages, and can apply quasi-continuous control curves Action events call arbitrary Python functions","title":"Event types"},{"location":"_isobar/events/action/","text":"Action events Action events trigger Python functions. Set the action property to a function or lambda, and it will be executed at the time of the event: timeline . schedule ({ \"action\" : lambda : print ( \"Hello world\" ) }) Observe that, when you run the above, it will print Hello world indefinitely, once per beat. Why is this? Just as for notes and other event types, the duration parameter of the event template defaults to an infinitely-repeating pattern generated by PConstant . To limit the number of repeats that an action performs, use the count argument: timeline . schedule ({ \"action\" : lambda : print ( round ( timeline . current_time )) }, count = 4 ) Action arguments For more complex functions, custom named keyword arguments can be passed to the function using the args property This executes an action every 4 beats to change the global key of the piece, using the Globals variables: def set_key ( k ): iso . Globals . set ( \"key\" , iso . Key ( key )) timeline . schedule ({ \"action\" : set_key , \"args\" : { \"k\" : iso . PWhite ( 8 ) }, \"duration\" : 4 }) timeline . schedule ({ \"degree\" : 0 , \"key\" : iso . PGlobals ( \"key\" ), \"octave\" : 4 })","title":"Action events"},{"location":"_isobar/events/action/#action-events","text":"Action events trigger Python functions. Set the action property to a function or lambda, and it will be executed at the time of the event: timeline . schedule ({ \"action\" : lambda : print ( \"Hello world\" ) }) Observe that, when you run the above, it will print Hello world indefinitely, once per beat. Why is this? Just as for notes and other event types, the duration parameter of the event template defaults to an infinitely-repeating pattern generated by PConstant . To limit the number of repeats that an action performs, use the count argument: timeline . schedule ({ \"action\" : lambda : print ( round ( timeline . current_time )) }, count = 4 )","title":"Action events"},{"location":"_isobar/events/action/#action-arguments","text":"For more complex functions, custom named keyword arguments can be passed to the function using the args property This executes an action every 4 beats to change the global key of the piece, using the Globals variables: def set_key ( k ): iso . Globals . set ( \"key\" , iso . Key ( key )) timeline . schedule ({ \"action\" : set_key , \"args\" : { \"k\" : iso . PWhite ( 8 ) }, \"duration\" : 4 }) timeline . schedule ({ \"degree\" : 0 , \"key\" : iso . PGlobals ( \"key\" ), \"octave\" : 4 })","title":"Action arguments"},{"location":"_isobar/events/control/","text":"Control events MIDI control change events can be sequenced by specifying the integer control index and the value to set the control change to: timeline . schedule ({ \"control\" : 0 , \"value\" : iso . PWhite ( 0 , 128 ), \"duration\" : 0.5 }) The above example sets control index 0 to a value drawn from a uniformly distribution, once every half-beat. Interpolation To transmit smooth control curves, isobar can interpolate between control values. The resulting interpolated value is sent continuously to the output device. # Apply linear interpolation to smoothly fade between values. timeline . schedule ({ \"control\" : 0 , \"value\" : iso . PWhite ( 0 , 128 ), \"duration\" : 0.5 }, interpolate = \"linear\" ) To jump instantaneously between values when interpolation is being used, simply set a duration of zero. The below applies sawtooth-shaped modulation to a control signal. timeline . schedule ({ \"control\" : 0 , \"value\" : iso . PSequence ([ 0 , 127 ]), \"duration\" : iso . PSequence ([ 1 , 0 ]) }, interpolate = \"linear\" ) Interpolation modes include: linear cosine","title":"Control events"},{"location":"_isobar/events/control/#control-events","text":"MIDI control change events can be sequenced by specifying the integer control index and the value to set the control change to: timeline . schedule ({ \"control\" : 0 , \"value\" : iso . PWhite ( 0 , 128 ), \"duration\" : 0.5 }) The above example sets control index 0 to a value drawn from a uniformly distribution, once every half-beat.","title":"Control events"},{"location":"_isobar/events/control/#interpolation","text":"To transmit smooth control curves, isobar can interpolate between control values. The resulting interpolated value is sent continuously to the output device. # Apply linear interpolation to smoothly fade between values. timeline . schedule ({ \"control\" : 0 , \"value\" : iso . PWhite ( 0 , 128 ), \"duration\" : 0.5 }, interpolate = \"linear\" ) To jump instantaneously between values when interpolation is being used, simply set a duration of zero. The below applies sawtooth-shaped modulation to a control signal. timeline . schedule ({ \"control\" : 0 , \"value\" : iso . PSequence ([ 0 , 127 ]), \"duration\" : iso . PSequence ([ 1 , 0 ]) }, interpolate = \"linear\" ) Interpolation modes include: linear cosine","title":"Interpolation"},{"location":"_isobar/events/note/","text":"Notes and MIDI events Notes and names A common approach to composition in isobar is building up patterns of notes, which correspond to the standard MIDI note range (0..127, with 60 = middle C) and velocity range (0..127). timeline . schedule ({ \"note\" : iso . PSequence ([ 60 , 64 , 67 , 72 ], 1 ), \"amplitude\" : 64 }) To get a note from its string representation, use the note_name_to_midi_note utility function: >>> print ( iso . note_name_to_midi_note ( \"G#2\" )) 32 Note events support the following properties: property type description note int MIDI note value amplitude int MIDI note velocity duration float Interval between notes (seconds) gate float Proportion of note to sustain (where 1.0 = legato) key Key Key for degree lookup scale Scale Scale for degree lookup degree int Degree within key/scale (cannot be used if note is specified) transpose int MIDI note transpose octave int MIDI note octave transpose Duration and gate The duration specifies the interval between one note and the next. The gate key specifies what proportion of this interval the note will be sustained for (and defaults to 1.0, for seamless legato). For instance: #-------------------------------------------------------------------------------- # Play a note every beat, sustained for half a beat #-------------------------------------------------------------------------------- timeline . schedule ({ \"note\" : 60 \"duration\" : 1 , \"gate\" : 0.5 }) The gate can also be greater than 1, to hold a note down as the next note begins: #-------------------------------------------------------------------------------- # Play a sustained, overlapping chord, with each note lasting for 4 beats #-------------------------------------------------------------------------------- timeline . schedule ({ \"note\" : iso . PSequence ([ 60 , 64 , 67 , 72 ], 1 ), \"duration\" : 0.5 , \"gate\" : 8 }) Keys and Scales isobar has builtin objects representing musical keys and scales. Scale encapsulates an ordered set of semitones. Named scales are defined corresponding to commonly-used scales ( major , minor , chromatic , aeolian , etc). Key encapsulates a Scale with a specified tonic. Warning isobar currently only supports equal temperament tuning. Keys and scales can be used in events by using the degree key to look up a specific degree within the key/scale. transpose and octave can be used to transpose by semitones and octaves respectively. #-------------------------------------------------------------------------------- # Play an F minor arpeggio #-------------------------------------------------------------------------------- timeline . schedule ({ \"degree\" : iso . PSequence ([ 0 , 2 , 4 , 7 ], 1 ), \"key\" : iso . Key ( \"F\" , \"minor\" ), \"octave\" : 4 }) Chords Chords can be specified by passing tuples of notes to the note or degree property. #-------------------------------------------------------------------------------- # Play a series of 3-note chords. #-------------------------------------------------------------------------------- timeline . schedule ({ \"degree\" : iso . PSequence ([ ( 0 , 1 , 4 ), ( 1 , 4 , 6 ), ( 3 , 4 , 7 ), ( - 1 , 0 , 4 ), ]), \"octave\" : 4 , \"duration\" : 2 }) You can also specify different amplitudes or gates for notes of a chord by passing tuples of the same length: timeline . schedule ({ \"note\" : iso . PSequence ([ ( 60 , 62 , 67 ), ]), \"gate\" : iso . PSequence ([ ( 0.25 , 0.5 , 1 ) ]), \"amplitude\" : iso . PSequence ([ ( 96 , 64 , 32 ), ( 64 , 96 , 32 ), ( 64 , 32 , 96 ), ]), \"duration\" : 0.25 }) Rests Use None to specify a rest: timeline . schedule ({ \"note\" : iso . PSequence ([ 60 , 60 , None , 60 , None , 60 , 60 , None ]), \"duration\" : 0.25 }) Many Pattern classes can operate explicitly on rests, or introduce rests. For example: PCollapse takes an input and steps past any rests to remove gaps PSkipIf replaces notes with rests given a conditional PSkip replaces notes with rests randomly given a probability PPad pads a sequence with rests until it reaches a specified length","title":"Notes and MIDI events"},{"location":"_isobar/events/note/#notes-and-midi-events","text":"","title":"Notes and MIDI events"},{"location":"_isobar/events/note/#notes-and-names","text":"A common approach to composition in isobar is building up patterns of notes, which correspond to the standard MIDI note range (0..127, with 60 = middle C) and velocity range (0..127). timeline . schedule ({ \"note\" : iso . PSequence ([ 60 , 64 , 67 , 72 ], 1 ), \"amplitude\" : 64 }) To get a note from its string representation, use the note_name_to_midi_note utility function: >>> print ( iso . note_name_to_midi_note ( \"G#2\" )) 32 Note events support the following properties: property type description note int MIDI note value amplitude int MIDI note velocity duration float Interval between notes (seconds) gate float Proportion of note to sustain (where 1.0 = legato) key Key Key for degree lookup scale Scale Scale for degree lookup degree int Degree within key/scale (cannot be used if note is specified) transpose int MIDI note transpose octave int MIDI note octave transpose","title":"Notes and names"},{"location":"_isobar/events/note/#duration-and-gate","text":"The duration specifies the interval between one note and the next. The gate key specifies what proportion of this interval the note will be sustained for (and defaults to 1.0, for seamless legato). For instance: #-------------------------------------------------------------------------------- # Play a note every beat, sustained for half a beat #-------------------------------------------------------------------------------- timeline . schedule ({ \"note\" : 60 \"duration\" : 1 , \"gate\" : 0.5 }) The gate can also be greater than 1, to hold a note down as the next note begins: #-------------------------------------------------------------------------------- # Play a sustained, overlapping chord, with each note lasting for 4 beats #-------------------------------------------------------------------------------- timeline . schedule ({ \"note\" : iso . PSequence ([ 60 , 64 , 67 , 72 ], 1 ), \"duration\" : 0.5 , \"gate\" : 8 })","title":"Duration and gate"},{"location":"_isobar/events/note/#keys-and-scales","text":"isobar has builtin objects representing musical keys and scales. Scale encapsulates an ordered set of semitones. Named scales are defined corresponding to commonly-used scales ( major , minor , chromatic , aeolian , etc). Key encapsulates a Scale with a specified tonic. Warning isobar currently only supports equal temperament tuning. Keys and scales can be used in events by using the degree key to look up a specific degree within the key/scale. transpose and octave can be used to transpose by semitones and octaves respectively. #-------------------------------------------------------------------------------- # Play an F minor arpeggio #-------------------------------------------------------------------------------- timeline . schedule ({ \"degree\" : iso . PSequence ([ 0 , 2 , 4 , 7 ], 1 ), \"key\" : iso . Key ( \"F\" , \"minor\" ), \"octave\" : 4 })","title":"Keys and Scales"},{"location":"_isobar/events/note/#chords","text":"Chords can be specified by passing tuples of notes to the note or degree property. #-------------------------------------------------------------------------------- # Play a series of 3-note chords. #-------------------------------------------------------------------------------- timeline . schedule ({ \"degree\" : iso . PSequence ([ ( 0 , 1 , 4 ), ( 1 , 4 , 6 ), ( 3 , 4 , 7 ), ( - 1 , 0 , 4 ), ]), \"octave\" : 4 , \"duration\" : 2 }) You can also specify different amplitudes or gates for notes of a chord by passing tuples of the same length: timeline . schedule ({ \"note\" : iso . PSequence ([ ( 60 , 62 , 67 ), ]), \"gate\" : iso . PSequence ([ ( 0.25 , 0.5 , 1 ) ]), \"amplitude\" : iso . PSequence ([ ( 96 , 64 , 32 ), ( 64 , 96 , 32 ), ( 64 , 32 , 96 ), ]), \"duration\" : 0.25 })","title":"Chords"},{"location":"_isobar/events/note/#rests","text":"Use None to specify a rest: timeline . schedule ({ \"note\" : iso . PSequence ([ 60 , 60 , None , 60 , None , 60 , 60 , None ]), \"duration\" : 0.25 }) Many Pattern classes can operate explicitly on rests, or introduce rests. For example: PCollapse takes an input and steps past any rests to remove gaps PSkipIf replaces notes with rests given a conditional PSkip replaces notes with rests randomly given a probability PPad pads a sequence with rests until it reaches a specified length","title":"Rests"},{"location":"_isobar/patterns/","text":"Patterns About patterns Patterns are the fundamental building blocks that are used to create melodies, rhythms and control sequences. A pattern is a Python iterator , which is to say it does two things: generates and returns the next item in the sequence when no more items are available in the sequence, raises a StopIteration exception >>> seq = iso . PSequence ([ 1 , 2 , 3 ], 1 ) >>> next ( seq ) 1 >>> next ( seq ) 2 >>> next ( seq ) 3 >>> next ( seq ) Traceback ( most recent call last ): File \"sequence.py\" , line 46 , in __next__ raise StopIteration StopIteration Note that this means that patterns can't seek backwards in time. Their only concern is generating the next event. By assigning patterns to properties of events , you can specify sequences of values to control any aspect of the control output: pitch, velocity, duration, etc. Patterns can be finite, such as the example above, or infinite, in which case they will keep generating new values forever. Patterns can also typically generate different Python types. Some Pattern classes will seek to do the right thing based on whether they are passed them int or float arguments. PSequence([ \"apple\", \"pear\" ]) generates an alternating pair of strings PWhite(0, 10) generates a stream of ints between [0 .. 9] PWhite(0.0, 10.0) generates a stream of floats between [0.0 .. 10.0] PChoice([ Key(\"C\", \"major\"), Key(\"A\", \"minor\") ]) picks one of the specified Key s at random Pattern resolution When a pattern returns a pattern, the embedded pattern will also be resolved recursively. For example: PChoice([ PSequence([0, 2, 3]), PSequence([7, 5, 2 ]) ]) each step, picks one of the embedded patterns and returns its next value Pattern operators Patterns can be combined and modified using standard Python arithmetic operators, with other patterns or with scalar values. >>> added = iso . PSequence ([ 1 , 2 , 3 ]) + 10 >>> next ( added ) 11 >>> next ( added ) 12 >>> multiplied = iso . PSequence ([ 1 , 2 , 3 ]) * 4 >>> next ( added ) 4 >>> next ( added ) 8 >>> inverted = 12 - iso . PSequence ([ 1 , 2 , 3 ]) >>> next ( inverted ) 11 >>> next ( inverted ) 10 combined = iso . PSequence ([ 1 , 2 , 3 ]) + iso . PSequence ([ 12 , 0 , 12 ]) >>> next ( combined ) 13 >>> next ( combined ) 2 The operators are designed to do what you would expect: binary operators ( + , - , * , / , % , << , >> ) perform the operation on each item of the input patterns. Note that, for binary operators, if either of the inputs returns None , the output value becomes None . equality operators ( < , > , == , != ) can be used to do element-wise comparison on the input sequences, returning a pattern whose values are either True , False or None . abs() can be used to generate the absolute values of a sequence For finite sequences, len() will return the length of the sequence A float pattern can be turned into an int pattern with isobar.PInt(pattern) Duplicating patterns It's often useful to be able to apply the same pattern to multiple properties or events. However, this can result in unwanted behaviours as shown below: >>> a = iso . PSequence ([ 1 , 2 , 3 ]) >>> d = iso . PDict ({ \"p1\" : a , \"p2\" : a }) >>> next ( d ) { 'p1' : 1 , 'p2' : 2 } Because the \"p1\" and \"p2\" properties both refer to the same instance, the next() method is called twice on a . Instead, use a.copy() to create a duplicate with identical state: >>> a = iso . PSequence ([ 1 , 2 , 3 ]) >>> d = iso . PDict ({ \"p1\" : a . copy (), \"p2\" : a . copy () }) >>> next ( d ) { 'p1' : 1 , 'p2' : 1 } Resetting a pattern To rewind a pattern to its initial state, call pattern.reset() . This restores all state variables to their original values. Stochastic patterns Stochastic patterns each have their own independent random number generator state. This allows them to be seeded with a known value to create repeatable pseudo-random number sequences. >>> a = iso . PWhite ( 0 , 10 ) >>> a . seed ( 123 ) >>> a . nextn ( 16 ) [ 0 , 0 , 4 , 1 , 9 , 0 , 5 , 3 , 8 , 1 , 3 , 3 , 2 , 0 , 4 , 0 ] >>> a . seed ( 123 ) >>> a . nextn ( 16 ) [ 0 , 0 , 4 , 1 , 9 , 0 , 5 , 3 , 8 , 1 , 3 , 3 , 2 , 0 , 4 , 0 ] Static patterns The state of a regular pattern steps forward each time the next() method is called. The state of a static pattern, conversely, is not modified by a call to next() . This means that next() may be called multiple times and return the same value each time. Static pattern classes include: PStaticPattern : When called as PStaticPattern(pattern, duration) , wraps a regular pattern and returns a new static pattern. Each new value of the inner pattern is returned for a specified duration in beats (see example below). The duration parameter may also be a pattern. PCurrentTime : Returns the current Timeline's time, in beats. PGlobals : See Globals . Static patterns can be used to impose temporal structure on a piece. For example, to modulate over a set of keys: #-------------------------------------------------------------------------------- # Create a pattern which is an alternating pair of Keys. #-------------------------------------------------------------------------------- key_sequence = iso . PSequence ([ iso . Key ( \"C\" , \"minor\" ), iso . Key ( \"G\" , \"major\" ), ]) #-------------------------------------------------------------------------------- # Create a static pattern embeds the key_sequence pattern. # Each value will be held for 4 beats before progressing to the next value. #-------------------------------------------------------------------------------- key_static = iso . PStaticPattern ( key_sequence , 4 ) #-------------------------------------------------------------------------------- # Schedule a pattern which plays notes following the given keys. # A \"C\" note will be played for 4 notes, followed by a \"G\" for 4 notes, # repeatedly. The same static pattern can be accessed by multiple different # tracks or timelines to orchestrate changes across the composition. #-------------------------------------------------------------------------------- timeline = iso . Timeline ( 120 ) timeline . schedule ({ \"degree\" : 0 , \"octave\" : 5 \"key\" : key_static , }) Globals The Globals class, and accompanying PGlobals pattern, can be used to share common variables across an isobar composition. For example: #-------------------------------------------------------------------------------- # Create a stream of events that will skip each note based on a \"density\" # global, with a key set by the \"key\" global. #-------------------------------------------------------------------------------- iso . Globals . set ( \"density\" , 0.5 ) iso . Globals . set ( \"key\" , iso . Key ( \"A\" , \"minor\" )) p = iso . PDict ({ \"degree\" : iso . PSkip ( 0 , iso . PGlobals ( \"density\" )), \"key\" : iso . PGlobals ( \"key\" ) })","title":"Patterns"},{"location":"_isobar/patterns/#patterns","text":"","title":"Patterns"},{"location":"_isobar/patterns/#about-patterns","text":"Patterns are the fundamental building blocks that are used to create melodies, rhythms and control sequences. A pattern is a Python iterator , which is to say it does two things: generates and returns the next item in the sequence when no more items are available in the sequence, raises a StopIteration exception >>> seq = iso . PSequence ([ 1 , 2 , 3 ], 1 ) >>> next ( seq ) 1 >>> next ( seq ) 2 >>> next ( seq ) 3 >>> next ( seq ) Traceback ( most recent call last ): File \"sequence.py\" , line 46 , in __next__ raise StopIteration StopIteration Note that this means that patterns can't seek backwards in time. Their only concern is generating the next event. By assigning patterns to properties of events , you can specify sequences of values to control any aspect of the control output: pitch, velocity, duration, etc. Patterns can be finite, such as the example above, or infinite, in which case they will keep generating new values forever. Patterns can also typically generate different Python types. Some Pattern classes will seek to do the right thing based on whether they are passed them int or float arguments. PSequence([ \"apple\", \"pear\" ]) generates an alternating pair of strings PWhite(0, 10) generates a stream of ints between [0 .. 9] PWhite(0.0, 10.0) generates a stream of floats between [0.0 .. 10.0] PChoice([ Key(\"C\", \"major\"), Key(\"A\", \"minor\") ]) picks one of the specified Key s at random","title":"About patterns"},{"location":"_isobar/patterns/#pattern-resolution","text":"When a pattern returns a pattern, the embedded pattern will also be resolved recursively. For example: PChoice([ PSequence([0, 2, 3]), PSequence([7, 5, 2 ]) ]) each step, picks one of the embedded patterns and returns its next value","title":"Pattern resolution"},{"location":"_isobar/patterns/#pattern-operators","text":"Patterns can be combined and modified using standard Python arithmetic operators, with other patterns or with scalar values. >>> added = iso . PSequence ([ 1 , 2 , 3 ]) + 10 >>> next ( added ) 11 >>> next ( added ) 12 >>> multiplied = iso . PSequence ([ 1 , 2 , 3 ]) * 4 >>> next ( added ) 4 >>> next ( added ) 8 >>> inverted = 12 - iso . PSequence ([ 1 , 2 , 3 ]) >>> next ( inverted ) 11 >>> next ( inverted ) 10 combined = iso . PSequence ([ 1 , 2 , 3 ]) + iso . PSequence ([ 12 , 0 , 12 ]) >>> next ( combined ) 13 >>> next ( combined ) 2 The operators are designed to do what you would expect: binary operators ( + , - , * , / , % , << , >> ) perform the operation on each item of the input patterns. Note that, for binary operators, if either of the inputs returns None , the output value becomes None . equality operators ( < , > , == , != ) can be used to do element-wise comparison on the input sequences, returning a pattern whose values are either True , False or None . abs() can be used to generate the absolute values of a sequence For finite sequences, len() will return the length of the sequence A float pattern can be turned into an int pattern with isobar.PInt(pattern)","title":"Pattern operators"},{"location":"_isobar/patterns/#duplicating-patterns","text":"It's often useful to be able to apply the same pattern to multiple properties or events. However, this can result in unwanted behaviours as shown below: >>> a = iso . PSequence ([ 1 , 2 , 3 ]) >>> d = iso . PDict ({ \"p1\" : a , \"p2\" : a }) >>> next ( d ) { 'p1' : 1 , 'p2' : 2 } Because the \"p1\" and \"p2\" properties both refer to the same instance, the next() method is called twice on a . Instead, use a.copy() to create a duplicate with identical state: >>> a = iso . PSequence ([ 1 , 2 , 3 ]) >>> d = iso . PDict ({ \"p1\" : a . copy (), \"p2\" : a . copy () }) >>> next ( d ) { 'p1' : 1 , 'p2' : 1 }","title":"Duplicating patterns"},{"location":"_isobar/patterns/#resetting-a-pattern","text":"To rewind a pattern to its initial state, call pattern.reset() . This restores all state variables to their original values.","title":"Resetting a pattern"},{"location":"_isobar/patterns/#stochastic-patterns","text":"Stochastic patterns each have their own independent random number generator state. This allows them to be seeded with a known value to create repeatable pseudo-random number sequences. >>> a = iso . PWhite ( 0 , 10 ) >>> a . seed ( 123 ) >>> a . nextn ( 16 ) [ 0 , 0 , 4 , 1 , 9 , 0 , 5 , 3 , 8 , 1 , 3 , 3 , 2 , 0 , 4 , 0 ] >>> a . seed ( 123 ) >>> a . nextn ( 16 ) [ 0 , 0 , 4 , 1 , 9 , 0 , 5 , 3 , 8 , 1 , 3 , 3 , 2 , 0 , 4 , 0 ]","title":"Stochastic patterns"},{"location":"_isobar/patterns/#static-patterns","text":"The state of a regular pattern steps forward each time the next() method is called. The state of a static pattern, conversely, is not modified by a call to next() . This means that next() may be called multiple times and return the same value each time. Static pattern classes include: PStaticPattern : When called as PStaticPattern(pattern, duration) , wraps a regular pattern and returns a new static pattern. Each new value of the inner pattern is returned for a specified duration in beats (see example below). The duration parameter may also be a pattern. PCurrentTime : Returns the current Timeline's time, in beats. PGlobals : See Globals . Static patterns can be used to impose temporal structure on a piece. For example, to modulate over a set of keys: #-------------------------------------------------------------------------------- # Create a pattern which is an alternating pair of Keys. #-------------------------------------------------------------------------------- key_sequence = iso . PSequence ([ iso . Key ( \"C\" , \"minor\" ), iso . Key ( \"G\" , \"major\" ), ]) #-------------------------------------------------------------------------------- # Create a static pattern embeds the key_sequence pattern. # Each value will be held for 4 beats before progressing to the next value. #-------------------------------------------------------------------------------- key_static = iso . PStaticPattern ( key_sequence , 4 ) #-------------------------------------------------------------------------------- # Schedule a pattern which plays notes following the given keys. # A \"C\" note will be played for 4 notes, followed by a \"G\" for 4 notes, # repeatedly. The same static pattern can be accessed by multiple different # tracks or timelines to orchestrate changes across the composition. #-------------------------------------------------------------------------------- timeline = iso . Timeline ( 120 ) timeline . schedule ({ \"degree\" : 0 , \"octave\" : 5 \"key\" : key_static , })","title":"Static patterns"},{"location":"_isobar/patterns/#globals","text":"The Globals class, and accompanying PGlobals pattern, can be used to share common variables across an isobar composition. For example: #-------------------------------------------------------------------------------- # Create a stream of events that will skip each note based on a \"density\" # global, with a key set by the \"key\" global. #-------------------------------------------------------------------------------- iso . Globals . set ( \"density\" , 0.5 ) iso . Globals . set ( \"key\" , iso . Key ( \"A\" , \"minor\" )) p = iso . PDict ({ \"degree\" : iso . PSkip ( 0 , iso . PGlobals ( \"density\" )), \"key\" : iso . PGlobals ( \"key\" ) })","title":"Globals"},{"location":"_isobar/patterns/library/","text":"Core View source: core.py Class Function Pattern Abstract superclass of all pattern generators. PConstant Returns a fixed value. PRef Contains a reference to another pattern, which can be replaced dynamically. PFunc Returns the value generated by a function. PArrayIndex Request a specified index from an array. PDict Construct a pattern from a dict of arrays, or an array of dicts. PDictKey Request a specified key from a dictionary. PConcatenate Concatenate the output of multiple sequences. PAbs Absolute value of input PInt Integer value of input PAdd Add elements of two patterns (shorthand: patternA + patternB) PSub Subtract elements of two patterns (shorthand: patternA - patternB) PMul Multiply elements of two patterns (shorthand: patternA * patternB) PDiv Divide elements of two patterns (shorthand: patternA / patternB) PFloorDiv Integer division (shorthand: patternA // patternB) PMod Modulo elements of two patterns (shorthand: patternA % patternB) PPow One pattern to the power of another (shorthand: patternA ** patternB) PLShift Binary left-shift (shorthand: patternA << patternB) PRShift Binary right-shift (shorthand: patternA << patternB) PEqual Return 1 if a == b, 0 otherwise (shorthand: patternA == patternB) PGreaterThanOrEqual Return 1 if a != b, 0 otherwise (shorthand: patternA != patternB) PGreaterThan Return 1 if a > b, 0 otherwise (shorthand: patternA > patternB) PGreaterThanOrEqual Return 1 if a >= b, 0 otherwise (shorthand: patternA >= patternB) PLessThan Return 1 if a < b, 0 otherwise (shorthand: patternA < patternB) PLessThanOrEqual Return 1 if a <= b, 0 otherwise (shorthand: patternA <= patternB) Scalar View source: scalar.py Class Function PChanged Outputs a 1 if the value of a pattern has changed. PDiff Outputs the difference between the current and previous values of an input pattern PSkipIf If skip is false, returns input ; otherwise, returns None. PNormalise Adaptively normalise input to [0..1] over a linear scale. PMap Apply an arbitrary function to an input pattern. PMapEnumerated Apply arbitrary function to input, passing a counter. PLinLin Map input from linear range [a,b] to linear range [c,d]. PLinExp Map input from linear range [a,b] to exponential range [c,d]. PRound Round input to N decimal places. PScalar Reduce tuples and lists into single scalar values, PWrap Wrap input note values within , . PIndexOf Find index of items from pattern in Sequence View source: sequence.py Class Function PSeries Arithmetic series, beginning at start , increment by step PRange Similar to PSeries, but specify a max/step value. PGeom Geometric series, beginning at start , multiplied by step PImpulse Outputs a 1 every events, otherwise 0. PLoop Repeats a finite pattern for n repeats. PPingPong Ping-pong input pattern back and forth N times. PCreep Loop length -note segment, progressing creep notes after repeats repeats. PStutter Play each note of pattern count times. PSubsequence Returns a finite subsequence of an input pattern. PReverse Reverses a finite sequence. PReset Resets pattern whenever trigger is true PCounter Increments a counter by 1 for each zero-crossing in trigger . PCollapse Skip over any rests in input PNoRepeats Skip over repeated values in input PPad Pad pattern with rests until it reaches length length . PPadToMultiple Pad pattern with rests until its length is divisible by multiple . PArpeggiator Arpeggiator. PEuclidean Generate Euclidean rhythms. PPermut Generate every permutation of count input items. PPatternGeneratorAction Each time its pattern is exhausted, request a new pattern by calling . PSequenceAction Iterate over an array, perform a function, and repeat. Chance View source: chance.py Class Function PWhite White noise between min and max . PBrown Brownian noise. PWalk Random walk around list. PChoice Pick a random element from values , weighted by optional weights . PSample Pick multiple random elements from values , weighted by optional weights , PShuffle Shuffled list. PShuffleInput Every n steps, take n values from pattern and reorder. PSkip Skip events with some probability, 1 - . PFlipFlop flip a binary bit with some probability. PSwitchOne Capture length input values; loop, repeatedly switching two adjacent values. Tonal View source: tonal.py Class Function PDegree Map scale index to MIDI notes in . PFilterByKey Filter notes based on their presence in . PNearestNoteInKey Return the nearest note in . PMidiNoteToFrequency Map MIDI note to frequency value. Static View source: static.py Class Function PStaticGlobal Static global value identified by a string, with OSC listener. PGlobals Static global value identified by a string. PStaticCurrentTime Returns the position (in beats) of the current timeline. Fade View source: fade.py Class Function PFadeNotewise Fade a pattern in/out by introducing notes at a gradual rate. PFadeNotewiseRandom Fade a pattern in/out by gradually introducing random notes. Markov View source: markov.py Class Function PMarkov First-order Markov chain generator. Lsystem View source: lsystem.py Class Function PLSystem integer sequence derived from Lindenmayer systems Warp View source: warp.py Class Function PWInterpolate Requests a new target warp value from pattern every length beats PWSine Sinosoidal warp, period length beats, amplitude +/- . PWRallantando Exponential deceleration to times the current tempo over length beats.","title":"Library"},{"location":"_isobar/patterns/library/#core","text":"View source: core.py Class Function Pattern Abstract superclass of all pattern generators. PConstant Returns a fixed value. PRef Contains a reference to another pattern, which can be replaced dynamically. PFunc Returns the value generated by a function. PArrayIndex Request a specified index from an array. PDict Construct a pattern from a dict of arrays, or an array of dicts. PDictKey Request a specified key from a dictionary. PConcatenate Concatenate the output of multiple sequences. PAbs Absolute value of input PInt Integer value of input PAdd Add elements of two patterns (shorthand: patternA + patternB) PSub Subtract elements of two patterns (shorthand: patternA - patternB) PMul Multiply elements of two patterns (shorthand: patternA * patternB) PDiv Divide elements of two patterns (shorthand: patternA / patternB) PFloorDiv Integer division (shorthand: patternA // patternB) PMod Modulo elements of two patterns (shorthand: patternA % patternB) PPow One pattern to the power of another (shorthand: patternA ** patternB) PLShift Binary left-shift (shorthand: patternA << patternB) PRShift Binary right-shift (shorthand: patternA << patternB) PEqual Return 1 if a == b, 0 otherwise (shorthand: patternA == patternB) PGreaterThanOrEqual Return 1 if a != b, 0 otherwise (shorthand: patternA != patternB) PGreaterThan Return 1 if a > b, 0 otherwise (shorthand: patternA > patternB) PGreaterThanOrEqual Return 1 if a >= b, 0 otherwise (shorthand: patternA >= patternB) PLessThan Return 1 if a < b, 0 otherwise (shorthand: patternA < patternB) PLessThanOrEqual Return 1 if a <= b, 0 otherwise (shorthand: patternA <= patternB)","title":"Core"},{"location":"_isobar/patterns/library/#scalar","text":"View source: scalar.py Class Function PChanged Outputs a 1 if the value of a pattern has changed. PDiff Outputs the difference between the current and previous values of an input pattern PSkipIf If skip is false, returns input ; otherwise, returns None. PNormalise Adaptively normalise input to [0..1] over a linear scale. PMap Apply an arbitrary function to an input pattern. PMapEnumerated Apply arbitrary function to input, passing a counter. PLinLin Map input from linear range [a,b] to linear range [c,d]. PLinExp Map input from linear range [a,b] to exponential range [c,d]. PRound Round input to N decimal places. PScalar Reduce tuples and lists into single scalar values, PWrap Wrap input note values within , . PIndexOf Find index of items from pattern in","title":"Scalar"},{"location":"_isobar/patterns/library/#sequence","text":"View source: sequence.py Class Function PSeries Arithmetic series, beginning at start , increment by step PRange Similar to PSeries, but specify a max/step value. PGeom Geometric series, beginning at start , multiplied by step PImpulse Outputs a 1 every events, otherwise 0. PLoop Repeats a finite pattern for n repeats. PPingPong Ping-pong input pattern back and forth N times. PCreep Loop length -note segment, progressing creep notes after repeats repeats. PStutter Play each note of pattern count times. PSubsequence Returns a finite subsequence of an input pattern. PReverse Reverses a finite sequence. PReset Resets pattern whenever trigger is true PCounter Increments a counter by 1 for each zero-crossing in trigger . PCollapse Skip over any rests in input PNoRepeats Skip over repeated values in input PPad Pad pattern with rests until it reaches length length . PPadToMultiple Pad pattern with rests until its length is divisible by multiple . PArpeggiator Arpeggiator. PEuclidean Generate Euclidean rhythms. PPermut Generate every permutation of count input items. PPatternGeneratorAction Each time its pattern is exhausted, request a new pattern by calling . PSequenceAction Iterate over an array, perform a function, and repeat.","title":"Sequence"},{"location":"_isobar/patterns/library/#chance","text":"View source: chance.py Class Function PWhite White noise between min and max . PBrown Brownian noise. PWalk Random walk around list. PChoice Pick a random element from values , weighted by optional weights . PSample Pick multiple random elements from values , weighted by optional weights , PShuffle Shuffled list. PShuffleInput Every n steps, take n values from pattern and reorder. PSkip Skip events with some probability, 1 - . PFlipFlop flip a binary bit with some probability. PSwitchOne Capture length input values; loop, repeatedly switching two adjacent values.","title":"Chance"},{"location":"_isobar/patterns/library/#tonal","text":"View source: tonal.py Class Function PDegree Map scale index to MIDI notes in . PFilterByKey Filter notes based on their presence in . PNearestNoteInKey Return the nearest note in . PMidiNoteToFrequency Map MIDI note to frequency value.","title":"Tonal"},{"location":"_isobar/patterns/library/#static","text":"View source: static.py Class Function PStaticGlobal Static global value identified by a string, with OSC listener. PGlobals Static global value identified by a string. PStaticCurrentTime Returns the position (in beats) of the current timeline.","title":"Static"},{"location":"_isobar/patterns/library/#fade","text":"View source: fade.py Class Function PFadeNotewise Fade a pattern in/out by introducing notes at a gradual rate. PFadeNotewiseRandom Fade a pattern in/out by gradually introducing random notes.","title":"Fade"},{"location":"_isobar/patterns/library/#markov","text":"View source: markov.py Class Function PMarkov First-order Markov chain generator.","title":"Markov"},{"location":"_isobar/patterns/library/#lsystem","text":"View source: lsystem.py Class Function PLSystem integer sequence derived from Lindenmayer systems","title":"Lsystem"},{"location":"_isobar/patterns/library/#warp","text":"View source: warp.py Class Function PWInterpolate Requests a new target warp value from pattern every length beats PWSine Sinosoidal warp, period length beats, amplitude +/- . PWRallantando Exponential deceleration to times the current tempo over length beats.","title":"Warp"},{"location":"_isobar/timelines/","text":"Timelines A Timeline schedules and executes events following a clock. By default, a Timeline creates its own internal clock at a specified tempo: timeline = iso . Timeline ( 120 ) timeline . run () You can set and query the tempo using the tempo property: >>> timeline . tempo = 140 >>> print ( timeline . tempo ) 140 Sync from clock in A Timeline can be synchronised from an external MIDI clock: midi_in = MidiInputDevice () timeline = iso . Timeline ( clock_source = midi_in ) timeline . run () MIDI start and stop events will be followed. Querying the timeline's tempo will give an estimate of the current bpm based on a moving average. Sync to clock out You can also drive external MIDI clocks from a Timeline, by specifying the send_clock argument when creating the output device. output_device = iso . MidiOutputDevice ( send_clock = True ) timeline = iso . Timeline ( 120 , output_device = output_device ) timeline . run () Scheduling events Scheduling events is done by passing a dict to the Timeline.schedule() method, which creates a new Track on the timeline. A timeline can have an unlimited number of tracks (unless you specify a limit with the max_tracks property). #-------------------------------------------------------------------------------- # Play a series of 5 notes with random velocities. # Delay by 1 beat before playback. #-------------------------------------------------------------------------------- timeline = iso . Timeline ( 120 ) timeline . schedule ({ \"note\" : iso . PSequence ([ 60 , 67 , 72 , 77 , 84 ], 1 ), \"duration\" : 0.5 , \"amplitude\" : iso . PWhite ( 0 , 128 ) }, delay = 1 ) timeline . run () Scheduling can be quantized or delayed by passing args to the schedule() method: quantize=N : quantize to the next N beats before beginning playback. For example, quantize=1 will quantize to the next beat. quantize=0.25 will quantize to a quarter-beat. delay=N : delay by N beats before beginning playback. If quantize and delay are both specified, quantization is applied, and the event is scheduled delay beats after the quantization time. To limit the number of iterations of an event, pass the count property: timeline.schedule({ \"note\": iso.PSeries(0, 1) + 60 }, count=4) Clock resolution and accuracy isobar's internal clock by default has a resolution of 480 ticks per beat (PPQN), which equates to a timing precision of 1ms at 120bpm. High-precision scheduling in Python is inherently limited by Python's global interpreter lock (GIL), which means that sub-millisecond accuracy is unfortunately not possible. The good news is that, when using Python 3+, jitter is pretty low: the unit test suite verifies that the host device is able to keep time to +/- 1ms, and passes on Linux and macOS. Nonlinear time Time warping and nonlinear time is a work in progress.","title":"Timelines"},{"location":"_isobar/timelines/#timelines","text":"A Timeline schedules and executes events following a clock. By default, a Timeline creates its own internal clock at a specified tempo: timeline = iso . Timeline ( 120 ) timeline . run () You can set and query the tempo using the tempo property: >>> timeline . tempo = 140 >>> print ( timeline . tempo ) 140","title":"Timelines"},{"location":"_isobar/timelines/#sync-from-clock-in","text":"A Timeline can be synchronised from an external MIDI clock: midi_in = MidiInputDevice () timeline = iso . Timeline ( clock_source = midi_in ) timeline . run () MIDI start and stop events will be followed. Querying the timeline's tempo will give an estimate of the current bpm based on a moving average.","title":"Sync from clock in"},{"location":"_isobar/timelines/#sync-to-clock-out","text":"You can also drive external MIDI clocks from a Timeline, by specifying the send_clock argument when creating the output device. output_device = iso . MidiOutputDevice ( send_clock = True ) timeline = iso . Timeline ( 120 , output_device = output_device ) timeline . run ()","title":"Sync to clock out"},{"location":"_isobar/timelines/#scheduling-events","text":"Scheduling events is done by passing a dict to the Timeline.schedule() method, which creates a new Track on the timeline. A timeline can have an unlimited number of tracks (unless you specify a limit with the max_tracks property). #-------------------------------------------------------------------------------- # Play a series of 5 notes with random velocities. # Delay by 1 beat before playback. #-------------------------------------------------------------------------------- timeline = iso . Timeline ( 120 ) timeline . schedule ({ \"note\" : iso . PSequence ([ 60 , 67 , 72 , 77 , 84 ], 1 ), \"duration\" : 0.5 , \"amplitude\" : iso . PWhite ( 0 , 128 ) }, delay = 1 ) timeline . run () Scheduling can be quantized or delayed by passing args to the schedule() method: quantize=N : quantize to the next N beats before beginning playback. For example, quantize=1 will quantize to the next beat. quantize=0.25 will quantize to a quarter-beat. delay=N : delay by N beats before beginning playback. If quantize and delay are both specified, quantization is applied, and the event is scheduled delay beats after the quantization time. To limit the number of iterations of an event, pass the count property: timeline.schedule({ \"note\": iso.PSeries(0, 1) + 60 }, count=4)","title":"Scheduling events"},{"location":"_isobar/timelines/#clock-resolution-and-accuracy","text":"isobar's internal clock by default has a resolution of 480 ticks per beat (PPQN), which equates to a timing precision of 1ms at 120bpm. High-precision scheduling in Python is inherently limited by Python's global interpreter lock (GIL), which means that sub-millisecond accuracy is unfortunately not possible. The good news is that, when using Python 3+, jitter is pretty low: the unit test suite verifies that the host device is able to keep time to +/- 1ms, and passes on Linux and macOS.","title":"Clock resolution and accuracy"},{"location":"_isobar/timelines/#nonlinear-time","text":"Time warping and nonlinear time is a work in progress.","title":"Nonlinear time"},{"location":"buffer/","text":"Buffer Warning This documentation is a work-in-progress and may have sections that are missing or incomplete.","title":"Buffers"},{"location":"buffer/#buffer","text":"Warning This documentation is a work-in-progress and may have sections that are missing or incomplete.","title":"Buffer"},{"location":"graph/","text":"The AudioGraph AudioGraph is the global audio processing graph that schedules and performs the audio processing. It contains references to all of the Node and Patch objects that are currently active, and, when a new block of audio is requested by the system audio I/O layer, traverses the tree of nodes and generates new samples. \u2192 Next: Creating the graph","title":"The AudioGraph"},{"location":"graph/#the-audiograph","text":"AudioGraph is the global audio processing graph that schedules and performs the audio processing. It contains references to all of the Node and Patch objects that are currently active, and, when a new block of audio is requested by the system audio I/O layer, traverses the tree of nodes and generates new samples. \u2192 Next: Creating the graph","title":"The AudioGraph"},{"location":"graph/config/","text":"The AudioGraph Graph configuration There are a number of graph configuration parameters that can be used to change the global behaviour of the audio system. Parameter Description output_device_name The name of the audio output device to use. This must precisely match the device's name in your system. input_device_name The name of the input device to use. sample_rate The audio sample rate to use. output_buffer_size The size of the hardware output audio buffer, in samples. A larger buffer reduces the chance of buffer overflows and glitches, but at the cost of higher latency. Note that this config option merely specifies the preferred output buffer size, which may not be available in the system hardware. To check the actual buffer size used by the AudioGraph, query graph.output_buffer_size after instantiation. input_buffer_size The size of the hardware input audio buffer. cpu_usage_limit Imposes a hard limit on the CPU usage permitted by SignalFlow. If the estimated (single-core) CPU usage exceeds this value, no more nodes or patches can be created until it returns to below the limit. Floating-point value between 0..1, where 0.5 means 50% CPU. Configuring the graph programmatically To specify an alternative config, create and populate an AudioGraphConfig object before the graph is started: config = AudioGraphConfig() config.output_device_name = \"MacBook Pro Speakers\" config.sample_rate = 44100 config.output_buffer_size = 2048 graph = AudioGraph(config) Configuring the graph via ~/.signalflow/config To specify a configuration that is used by all future SignalFlow sessions, create a file ~/.signalflow/config with the following format: [audio] sample_rate = 48000 output_buffer_size = 256 input_buffer_size = 256 output_device_name = \"MacBook Pro Speakers\" input_device_name = \"MacBook Pro Microphone\" All fields are optional. \u2192 Next: Graph status and properties","title":"Configuration"},{"location":"graph/config/#the-audiograph","text":"","title":"The AudioGraph"},{"location":"graph/config/#graph-configuration","text":"There are a number of graph configuration parameters that can be used to change the global behaviour of the audio system. Parameter Description output_device_name The name of the audio output device to use. This must precisely match the device's name in your system. input_device_name The name of the input device to use. sample_rate The audio sample rate to use. output_buffer_size The size of the hardware output audio buffer, in samples. A larger buffer reduces the chance of buffer overflows and glitches, but at the cost of higher latency. Note that this config option merely specifies the preferred output buffer size, which may not be available in the system hardware. To check the actual buffer size used by the AudioGraph, query graph.output_buffer_size after instantiation. input_buffer_size The size of the hardware input audio buffer. cpu_usage_limit Imposes a hard limit on the CPU usage permitted by SignalFlow. If the estimated (single-core) CPU usage exceeds this value, no more nodes or patches can be created until it returns to below the limit. Floating-point value between 0..1, where 0.5 means 50% CPU.","title":"Graph configuration"},{"location":"graph/config/#configuring-the-graph-programmatically","text":"To specify an alternative config, create and populate an AudioGraphConfig object before the graph is started: config = AudioGraphConfig() config.output_device_name = \"MacBook Pro Speakers\" config.sample_rate = 44100 config.output_buffer_size = 2048 graph = AudioGraph(config)","title":"Configuring the graph programmatically"},{"location":"graph/config/#configuring-the-graph-via-signalflowconfig","text":"To specify a configuration that is used by all future SignalFlow sessions, create a file ~/.signalflow/config with the following format: [audio] sample_rate = 48000 output_buffer_size = 256 input_buffer_size = 256 output_device_name = \"MacBook Pro Speakers\" input_device_name = \"MacBook Pro Microphone\" All fields are optional. \u2192 Next: Graph status and properties","title":"Configuring the graph via ~/.signalflow/config"},{"location":"graph/creating/","text":"The AudioGraph Creating the graph Creating the graph is simple: graph = AudioGraph() By default, a new AudioGraph immediately connects to the system's default audio hardware device (via the integrated libsoundio library), using the system's default sample rate and buffer size. Info Note that the AudioGraph is a singleton object: only one AudioGraph can be created, which is shared globally. To prevent the graph from starting instantly (for example, if you want to use the graph in offline mode), pass start=False to the constructor. To configure graph playback or recording parameters, see AudioGraph: Configuration . \u2192 Next: Graph configuration","title":"Creating the graph"},{"location":"graph/creating/#the-audiograph","text":"","title":"The AudioGraph"},{"location":"graph/creating/#creating-the-graph","text":"Creating the graph is simple: graph = AudioGraph() By default, a new AudioGraph immediately connects to the system's default audio hardware device (via the integrated libsoundio library), using the system's default sample rate and buffer size. Info Note that the AudioGraph is a singleton object: only one AudioGraph can be created, which is shared globally. To prevent the graph from starting instantly (for example, if you want to use the graph in offline mode), pass start=False to the constructor. To configure graph playback or recording parameters, see AudioGraph: Configuration . \u2192 Next: Graph configuration","title":"Creating the graph"},{"location":"graph/properties/","text":"The AudioGraph Status and properties A number of methods are provided to query the graph's current status and properties. Status Querying graph.status returns a one-line description of the number of nodes and patches in the graph, and the estimated CPU and RAM usage: >>> graph.status AudioGraph: 235 active nodes, 6 patches, 13.95% CPU usage, 34.91MB memory usage To automatically poll and print the graph's status periodically, call graph.poll(interval) , where interval is in seconds: >>> graph.poll(1) AudioGraph: 118 active nodes, 3 patches, 7.09% CPU usage, 34.91MB memory usage AudioGraph: 118 active nodes, 3 patches, 7.16% CPU usage, 34.91MB memory usage AudioGraph: 40 active nodes, 1 patch, 2.60% CPU usage, 34.91MB memory usage To stop polling, call graph.poll(0) . Structure Querying graph.structure returns a multi-line string describing every Node in the graph, their parameter values, and their connectivity structure. >>> graph.structure * audioout-soundio input0: * linear-panner pan: 0.000000 input: * multiply input1: 0.251189 input0: * sine frequency: 440.000000 Other graph properties graph.node_count (int): Returns the current number of Nodes in the graph (including within patches) graph.patch_count (int): Returns the current number of Patches in the graph cpu_usage (float): Returns the current CPU usage, between 0.0 (0%) and 1.0 (100%). CPU usage can be lowered by increasing the output buffer size. memory_usage (int): Returns the current RAM usage, in bytes. This is typically mostly used by waveform data in Buffers . num_output_channels (int): Returns the graph's current output channel count, which is typically identical to the number of channels supported by the audio output device. output_buffer_size (int): Returns the current hardware output buffer size, in bytes. \u2192 Next: Recording graph output","title":"Status and properties"},{"location":"graph/properties/#the-audiograph","text":"","title":"The AudioGraph"},{"location":"graph/properties/#status-and-properties","text":"A number of methods are provided to query the graph's current status and properties.","title":"Status and properties"},{"location":"graph/properties/#status","text":"Querying graph.status returns a one-line description of the number of nodes and patches in the graph, and the estimated CPU and RAM usage: >>> graph.status AudioGraph: 235 active nodes, 6 patches, 13.95% CPU usage, 34.91MB memory usage To automatically poll and print the graph's status periodically, call graph.poll(interval) , where interval is in seconds: >>> graph.poll(1) AudioGraph: 118 active nodes, 3 patches, 7.09% CPU usage, 34.91MB memory usage AudioGraph: 118 active nodes, 3 patches, 7.16% CPU usage, 34.91MB memory usage AudioGraph: 40 active nodes, 1 patch, 2.60% CPU usage, 34.91MB memory usage To stop polling, call graph.poll(0) .","title":"Status"},{"location":"graph/properties/#structure","text":"Querying graph.structure returns a multi-line string describing every Node in the graph, their parameter values, and their connectivity structure. >>> graph.structure * audioout-soundio input0: * linear-panner pan: 0.000000 input: * multiply input1: 0.251189 input0: * sine frequency: 440.000000","title":"Structure"},{"location":"graph/properties/#other-graph-properties","text":"graph.node_count (int): Returns the current number of Nodes in the graph (including within patches) graph.patch_count (int): Returns the current number of Patches in the graph cpu_usage (float): Returns the current CPU usage, between 0.0 (0%) and 1.0 (100%). CPU usage can be lowered by increasing the output buffer size. memory_usage (int): Returns the current RAM usage, in bytes. This is typically mostly used by waveform data in Buffers . num_output_channels (int): Returns the graph's current output channel count, which is typically identical to the number of channels supported by the audio output device. output_buffer_size (int): Returns the current hardware output buffer size, in bytes. \u2192 Next: Recording graph output","title":"Other graph properties"},{"location":"graph/recording/","text":"The AudioGraph Recording the audio output of the graph Convenience methods are provided to make it easy to record the global audio output: graph . start_recording ( \"filename.wav\" ) ... graph . stop_recording () To record output in formats other than the default stereo, start_recording takes a num_channels argument that can be used to specify an alternative channel count. Note At present, only .wav is supported as an output format for global audio recordings. \u2192 Next: Clearing and stopping the graph","title":"Recording the audio output"},{"location":"graph/recording/#the-audiograph","text":"","title":"The AudioGraph"},{"location":"graph/recording/#recording-the-audio-output-of-the-graph","text":"Convenience methods are provided to make it easy to record the global audio output: graph . start_recording ( \"filename.wav\" ) ... graph . stop_recording () To record output in formats other than the default stereo, start_recording takes a num_channels argument that can be used to specify an alternative channel count. Note At present, only .wav is supported as an output format for global audio recordings. \u2192 Next: Clearing and stopping the graph","title":"Recording the audio output of the graph"},{"location":"graph/stopping/","text":"The AudioGraph Clearing and stopping the graph To clear all nodes and patches from the graph but leave it running for further audio synthesis: >>> graph.clear() To stop the graph and pause audio I/O: >>> graph.stop() To permanently destroy the graph: >>> graph.destroy()","title":"Stopping the graph"},{"location":"graph/stopping/#the-audiograph","text":"","title":"The AudioGraph"},{"location":"graph/stopping/#clearing-and-stopping-the-graph","text":"To clear all nodes and patches from the graph but leave it running for further audio synthesis: >>> graph.clear() To stop the graph and pause audio I/O: >>> graph.stop() To permanently destroy the graph: >>> graph.destroy()","title":"Clearing and stopping the graph"},{"location":"howto/","text":"Howto Warning This documentation is a work-in-progress and may have sections that are missing or incomplete. Tutorials on common tasks with SignalFlow.","title":"Howto"},{"location":"howto/#howto","text":"Warning This documentation is a work-in-progress and may have sections that are missing or incomplete. Tutorials on common tasks with SignalFlow.","title":"Howto"},{"location":"howto/midi/","text":"Howto: MIDI control","title":"Howto: MIDI control"},{"location":"howto/midi/#howto-midi-control","text":"","title":"Howto: MIDI control"},{"location":"node/","text":"Nodes A Node object is an audio processing unit that performs one single function. For example, a Node's role may be to synthesize a waveform, read from a buffer, or take two input Nodes and sum their values. Nodes are played and stopped by connecting them to the AudioGraph A node has one or more audio-rate inputs , which can be modulated by other nodes Some nodes can be triggered with trigger inputs \u2014 for example, to restart playback, or set the position of an envelope Some nodes can be used to play back the contents of buffer inputs , or can use buffer data as a source of modulation The output of multiple nodes can be combined and modulated with use of the standard Python operators (+, -, *, %, etc) The output of a node can be mono (single-channel) or multichannel A Node's status and output can be examined by querying its status and properties Some Nodes generate unpredictable stochastic output , which can be controlled via its internal random number generator Details of how to create a new Node type are detailed in Developing a new Node class For an overview of every type of Node available in SignalFlow, see the Node Reference Library \u2192 Next: Node playback","title":"Nodes"},{"location":"node/#nodes","text":"A Node object is an audio processing unit that performs one single function. For example, a Node's role may be to synthesize a waveform, read from a buffer, or take two input Nodes and sum their values. Nodes are played and stopped by connecting them to the AudioGraph A node has one or more audio-rate inputs , which can be modulated by other nodes Some nodes can be triggered with trigger inputs \u2014 for example, to restart playback, or set the position of an envelope Some nodes can be used to play back the contents of buffer inputs , or can use buffer data as a source of modulation The output of multiple nodes can be combined and modulated with use of the standard Python operators (+, -, *, %, etc) The output of a node can be mono (single-channel) or multichannel A Node's status and output can be examined by querying its status and properties Some Nodes generate unpredictable stochastic output , which can be controlled via its internal random number generator Details of how to create a new Node type are detailed in Developing a new Node class For an overview of every type of Node available in SignalFlow, see the Node Reference Library \u2192 Next: Node playback","title":"Nodes"},{"location":"node/developing/","text":"Nodes Developing new Node classes See CONTRIBUTING.md","title":"Developing a new Node class"},{"location":"node/developing/#nodes","text":"","title":"Nodes"},{"location":"node/developing/#developing-new-node-classes","text":"See CONTRIBUTING.md","title":"Developing new Node classes"},{"location":"node/inputs/","text":"Nodes Node inputs A node has three different classes of input: Audio-rate inputs : Takes the output of another node as an input, for continuous modulation of synthesis parameters Trigger inputs : Used to trigger discrete control events \u2014 for example, restarting buffer playback Buffer inputs : Used to pass the contents of an audio buffer to a node \u2014 for example, as a source of audio samples, or an envelope shape Audio-rate inputs Virtually every node has one or more audio-rate inputs. Put simply, an audio-rate input is the output of another node . Let's look at a short example: lfo = SineLFO () signal = SquareOscillator ( frequency = 200 , width = lfo ) In this case, we are passing the output of a SineLFO as the pulse width of a SquareOscillator . This is an audio-rate input. Although it's not obvious, the frequency parameter is also an audio-rate input. Any constant value (such as the 200 here) is behind the scenes implemented as a Constant node, which continuously outputs the value at an audio rate. All audio-rate inputs can be modified just like a normal Python property. For example: signal . frequency = TriangleOscillator ( 0.5 , 100 , 1000 ) Variable input nodes Some nodes have a variable number of inputs, which can change over the Node's lifetime. For example, Sum() takes an arbitrary number of input Nodes, and generates an output which is the sum of all of its inputs. For variable-input nodes such as this, audio-rate inputs are added with add_input() , and can be removed with remove_input() . a = Constant ( 1 ) b = Constant ( 2 ) c = Constant ( 3 ) sum = Sum () sum . add_input ( a ) sum . add_input ( b ) sum . add_input ( c ) # sum will now generate an output of 6.0 It is possible to check whether a Node object takes variable inputs by querying node.has_variable_inputs . Triggers When working with sequencing and timing, it is often useful be able to trigger discrete events within a node. This is where trigger inputs come in handy. There are two different ways to handle trigger inputs: by calling the trigger() method on a Node by passing a Node to an input that corresponds to an audio-rate trigger Calling trigger() To generate trigger events at arbitrary times, call node.trigger() . For example: freq_env = Line ( 10000 , 100 , 0.5 ) sine = SineOscillator ( freq_env ) sine . play () while True : freq_env . trigger () graph . wait ( 1 ) This is useful because it can be done outside the audio thread. For example, trigger() could be called each time a MIDI note event is received. The trigger() method takes an optional name parameter, which is used by Node classes containing more than one type of trigger. This example uses the set_position trigger of BufferPlayer to seek to a new location in the sample every second. buffer = Buffer ( \"../audio/stereo-count.wav\" ) player = BufferPlayer ( buffer , loop = True ) player . play () while True : player . trigger ( \"set_position\" , random_uniform ( 0 , buffer . duration )) graph . wait ( 1 ) Note Because the trigger method happens outside the audio thread, it will take effect at the start of the next audio block. This means that, if you are running at 44.1kHz with an audio buffer size of 1024 samples, this could introduce a latency of up to 1024/44100 = 0.023s . For time-critical events like drum triggers, this can be minimised by reducing the hardware output buffer size . This constraint also means that only one event can be triggered per audio block. To trigger events at a faster rate than the hardware buffer size allows, see Audio-rate triggers below. Audio-rate triggers It is often desirable to trigger events using the audio-rate output of another Node object as a source of trigger events, to give sample-level precision in timing. Most nodes that support trigger inputs can also be triggered by a corresponding audio-rate input. Triggers happen at zero-crossings \u2014 that is, when the output of the node passes above zero (i.e., from <= 0 to >0 ). For example, to create a clock with an oscillating tempo to re-trigger buffer playback: clock = Impulse ( SineLFO ( 0.2 , 1 , 10 )) buffer = Buffer ( \"../audio/stereo-count.wav\" ) player = BufferPlayer ( buffer , loop = True , clock = clock ) player . play () This can be used to your advantage with the boolean operator nodes. on_the_right = MouseX () > 0.5 envelope = ASREnvelope ( 0 , 0 , 0.5 , clock = on_the_right ) square = SquareOscillator ( 100 ) output = envelope * square * 0.1 output . play () TODO: Should the name of the trigger() event always be identical to the trigger input name? So clock for envelopes, buffer player, etc...? Buffer inputs The third type of input supported by nodes is the buffer . Nodes often take buffer inputs as sources of audio samples. They are also useful as sources of envelope shape data (for example, to shape the grains of a Granulator), or general control data (for example, recording motion patterns from a MouseX input). buffer = Buffer ( \"../audio/stereo-count.wav\" ) player = BufferPlayer ( buffer , loop = True ) \u2192 Next: Operators","title":"Inputs"},{"location":"node/inputs/#nodes","text":"","title":"Nodes"},{"location":"node/inputs/#node-inputs","text":"A node has three different classes of input: Audio-rate inputs : Takes the output of another node as an input, for continuous modulation of synthesis parameters Trigger inputs : Used to trigger discrete control events \u2014 for example, restarting buffer playback Buffer inputs : Used to pass the contents of an audio buffer to a node \u2014 for example, as a source of audio samples, or an envelope shape","title":"Node inputs"},{"location":"node/inputs/#audio-rate-inputs","text":"Virtually every node has one or more audio-rate inputs. Put simply, an audio-rate input is the output of another node . Let's look at a short example: lfo = SineLFO () signal = SquareOscillator ( frequency = 200 , width = lfo ) In this case, we are passing the output of a SineLFO as the pulse width of a SquareOscillator . This is an audio-rate input. Although it's not obvious, the frequency parameter is also an audio-rate input. Any constant value (such as the 200 here) is behind the scenes implemented as a Constant node, which continuously outputs the value at an audio rate. All audio-rate inputs can be modified just like a normal Python property. For example: signal . frequency = TriangleOscillator ( 0.5 , 100 , 1000 )","title":"Audio-rate inputs"},{"location":"node/inputs/#variable-input-nodes","text":"Some nodes have a variable number of inputs, which can change over the Node's lifetime. For example, Sum() takes an arbitrary number of input Nodes, and generates an output which is the sum of all of its inputs. For variable-input nodes such as this, audio-rate inputs are added with add_input() , and can be removed with remove_input() . a = Constant ( 1 ) b = Constant ( 2 ) c = Constant ( 3 ) sum = Sum () sum . add_input ( a ) sum . add_input ( b ) sum . add_input ( c ) # sum will now generate an output of 6.0 It is possible to check whether a Node object takes variable inputs by querying node.has_variable_inputs .","title":"Variable input nodes"},{"location":"node/inputs/#triggers","text":"When working with sequencing and timing, it is often useful be able to trigger discrete events within a node. This is where trigger inputs come in handy. There are two different ways to handle trigger inputs: by calling the trigger() method on a Node by passing a Node to an input that corresponds to an audio-rate trigger","title":"Triggers"},{"location":"node/inputs/#calling-trigger","text":"To generate trigger events at arbitrary times, call node.trigger() . For example: freq_env = Line ( 10000 , 100 , 0.5 ) sine = SineOscillator ( freq_env ) sine . play () while True : freq_env . trigger () graph . wait ( 1 ) This is useful because it can be done outside the audio thread. For example, trigger() could be called each time a MIDI note event is received. The trigger() method takes an optional name parameter, which is used by Node classes containing more than one type of trigger. This example uses the set_position trigger of BufferPlayer to seek to a new location in the sample every second. buffer = Buffer ( \"../audio/stereo-count.wav\" ) player = BufferPlayer ( buffer , loop = True ) player . play () while True : player . trigger ( \"set_position\" , random_uniform ( 0 , buffer . duration )) graph . wait ( 1 ) Note Because the trigger method happens outside the audio thread, it will take effect at the start of the next audio block. This means that, if you are running at 44.1kHz with an audio buffer size of 1024 samples, this could introduce a latency of up to 1024/44100 = 0.023s . For time-critical events like drum triggers, this can be minimised by reducing the hardware output buffer size . This constraint also means that only one event can be triggered per audio block. To trigger events at a faster rate than the hardware buffer size allows, see Audio-rate triggers below.","title":"Calling trigger()"},{"location":"node/inputs/#audio-rate-triggers","text":"It is often desirable to trigger events using the audio-rate output of another Node object as a source of trigger events, to give sample-level precision in timing. Most nodes that support trigger inputs can also be triggered by a corresponding audio-rate input. Triggers happen at zero-crossings \u2014 that is, when the output of the node passes above zero (i.e., from <= 0 to >0 ). For example, to create a clock with an oscillating tempo to re-trigger buffer playback: clock = Impulse ( SineLFO ( 0.2 , 1 , 10 )) buffer = Buffer ( \"../audio/stereo-count.wav\" ) player = BufferPlayer ( buffer , loop = True , clock = clock ) player . play () This can be used to your advantage with the boolean operator nodes. on_the_right = MouseX () > 0.5 envelope = ASREnvelope ( 0 , 0 , 0.5 , clock = on_the_right ) square = SquareOscillator ( 100 ) output = envelope * square * 0.1 output . play () TODO: Should the name of the trigger() event always be identical to the trigger input name? So clock for envelopes, buffer player, etc...?","title":"Audio-rate triggers"},{"location":"node/inputs/#buffer-inputs","text":"The third type of input supported by nodes is the buffer . Nodes often take buffer inputs as sources of audio samples. They are also useful as sources of envelope shape data (for example, to shape the grains of a Granulator), or general control data (for example, recording motion patterns from a MouseX input). buffer = Buffer ( \"../audio/stereo-count.wav\" ) player = BufferPlayer ( buffer , loop = True ) \u2192 Next: Operators","title":"Buffer inputs"},{"location":"node/library/","text":"Node reference library analysis CrossCorrelate (input=nullptr, buffer=nullptr, hop_size=0) OnsetDetector (input=0.0, threshold=2.0, min_interval=0.1) VampAnalysis (input=0.0, plugin_id=\"vamp-example-plugins:spectralcentroid:linearcentroid\") buffer BeatCutter (buffer=nullptr, segment_count=8, stutter_probability=0.0, stutter_count=1, jump_probability=0.0, duty_cycle=1.0, rate=1.0, segment_rate=1.0) BufferPlayer (buffer=nullptr, rate=1.0, loop=0, start_time=nullptr, end_time=nullptr, clock=nullptr) BufferRecorder (buffer=nullptr, input=0.0, feedback=0.0, loop=false) FeedbackBufferReader (buffer=nullptr) FeedbackBufferWriter (buffer=nullptr, input=0.0, delay_time=0.1) GrainSegments (buffer=nullptr, clock=0, target=0, offsets={}, values={}, durations={}) Granulator (buffer=nullptr, clock=0, pos=0, duration=0.1, pan=0.0, rate=1.0, max_grains=2048) SegmentPlayer (buffer=nullptr, onsets={}) control MouseX () MouseY () MouseDown (button_index=0) envelope ADSREnvelope (attack=0.1, decay=0.1, sustain=0.5, release=0.1, gate=0) ASREnvelope (attack=0.1, sustain=0.5, release=0.1, curve=1.0, clock=nullptr) Envelope (levels=std::vector<NodeRef> ( ), times=std::vector<NodeRef> ( ), curves=std::vector<NodeRef> ( ), clock=nullptr, loop=false) Line (from=0.0, to=1.0, time=1.0, loop=0, clock=nullptr) EnvelopeRect (sustain=1.0, clock=nullptr) fft FFTContinuousPhaseVocoder (input=nullptr, rate=1.0) FFTConvolve (input=nullptr, buffer=nullptr) FFT (input=0.0, fft_size=SIGNALFLOW_DEFAULT_FFT_SIZE, hop_size=SIGNALFLOW_DEFAULT_FFT_HOP_SIZE, window_size=0, do_window=true) FFTNode (fft_size=None, hop_size=None, window_size=None, do_window=None) FFTOpNode (input=nullptr) FFTFindPeaks (input=0, prominence=1, threshold=0.000001, count=SIGNALFLOW_MAX_CHANNELS, interpolate=true) IFFT (input=nullptr, do_window=false) FFTLPF (input=0, frequency=2000) FFTNoiseGate (input=0, threshold=0.5) FFTPhaseVocoder (input=nullptr) FFTTonality (input=0, level=0.5, smoothing=0.9) FFTZeroPhase (input=0) operators Add (a=0, b=0) AmplitudeToDecibels (a=0) DecibelsToAmplitude (a=0) ChannelArray () ChannelMixer (channels=1, input=0, amplitude_compensation=true) ChannelSelect (input=nullptr, offset=0, maximum=0, step=1) Equal (a=0, b=0) NotEqual (a=0, b=0) GreaterThan (a=0, b=0) GreaterThanOrEqual (a=0, b=0) LessThan (a=0, b=0) LessThanOrEqual (a=0, b=0) Modulo (a=0, b=0) Abs (a=0) If (a=0, value_if_true=0, value_if_false=0) Divide (a=1, b=1) FrequencyToMidiNote (a=0) MidiNoteToFrequency (a=0) Multiply (a=1.0, b=1.0) Pow (a=0, b=0) RoundToScale (a=0) Round (a=0) ScaleLinExp (input=0, a=0, b=1, c=1, d=10) ScaleLinLin (input=0, a=0, b=1, c=1, d=10) Subtract (a=0, b=0) Sum () Tanh (a=0) oscillators Constant (value=0) Impulse (frequency=1.0) LFO (frequency=1.0, min=0.0, max=1.0) SawLFO (frequency=1.0, min=0.0, max=1.0) SawOscillator (frequency=440) SineLFO (frequency=1.0, min=0.0, max=1.0) SineOscillator (frequency=440) SquareLFO (frequency=1.0, min=0.0, max=1.0, width=0.5) SquareOscillator (frequency=440, width=0.5) TriangleLFO (frequency=1.0, min=0.0, max=1.0) TriangleOscillator (frequency=440) Wavetable (buffer=nullptr, frequency=440, phase=0, sync=0, phase_map=nullptr) Wavetable2D (buffer=nullptr, frequency=440, crossfade=0.0, sync=0) processors Clip (input=nullptr, min=-1.0, max=1.0) processors/delays AllpassDelay (input=0.0, delaytime=0.1, feedback=0.5, maxdelaytime=0.5) CombDelay (input=0.0, delaytime=0.1, feedback=0.5, maxdelaytime=0.5) OneTapDelay (input=0.0, delaytime=0.1, maxdelaytime=0.5) Stutter (input=0.0, stutter_time=0.1, stutter_count=1, clock=nullptr, max_stutter_time=1.0) processors/distortion Resample (input=0, sample_rate=44100, bit_rate=16) SampleAndHold (input=nullptr, clock=nullptr) Squiz (input=0.0, rate=2.0, chunk_size=1) WaveShaper (input=0.0, buffer=nullptr) processors/dynamics Compressor (input=0.0, threshold=0.1, ratio=2, attack_time=0.01, release_time=0.1, sidechain=nullptr) Gate (input=0.0, threshold=0.1) Maximiser (input=0.0, ceiling=0.5, attack_time=1.0, release_time=1.0) RMS (input=0.0) processors/filters BiquadFilter (input=0.0, filter_type=SIGNALFLOW_FILTER_TYPE_LOW_PASS, cutoff=440, resonance=0.0, peak_gain=0.0) EQ (input=0.0, low_gain=1.0, mid_gain=1.0, high_gain=1.0, low_freq=500, high_freq=5000) MoogVCF (input=0.0, cutoff=200.0, resonance=0.0) SVFilter (input=0.0, filter_type=SIGNALFLOW_FILTER_TYPE_LOW_PASS, cutoff=440, resonance=0.0) processors Fold (input=nullptr, min=-1.0, max=1.0) processors/panning LinearPanner (channels=2, input=0, pan=0.0) StereoBalance (input=0, balance=0) StereoWidth (input=0, width=1) processors Smooth (input=nullptr, smooth=0.99) WetDry (dry_input=nullptr, wet_input=nullptr, wetness=0.0) Wrap (input=nullptr, min=-1.0, max=1.0) sequencing ClockDivider (clock=0, factor=1) Counter (clock=0, min=0, max=2147483647) Euclidean (clock=0, sequence_length=0, num_events=0) FlipFlop (clock=0) ImpulseSequence (sequence=std::vector<int> ( ), clock=nullptr) Index (list={}, index=0) Latch (set=0, reset=0) Sequence (sequence=std::vector<float> ( ), clock=nullptr) stochastic Logistic (chaos=3.7, frequency=0.0) PinkNoise (low_cutoff=20.0, high_cutoff=20000.0, reset=nullptr) RandomBrownian (min=-1.0, max=1.0, delta=0.01, clock=nullptr, reset=nullptr) RandomChoice (values=std::vector<float> ( ), clock=nullptr, reset=nullptr) RandomCoin (probability=0.5, clock=nullptr, reset=nullptr) RandomExponentialDist (scale=0.0, clock=nullptr, reset=nullptr) RandomExponential (min=0.001, max=1.0, clock=nullptr, reset=nullptr) RandomGaussian (mean=0.0, sigma=0.0, clock=nullptr, reset=nullptr) RandomImpulseSequence (probability=0.5, length=8, clock=nullptr, explore=nullptr, generate=nullptr, reset=nullptr) RandomImpulse (frequency=1.0, distribution=SIGNALFLOW_EVENT_DISTRIBUTION_UNIFORM, reset=nullptr) RandomUniform (min=0.0, max=1.0, clock=nullptr, reset=nullptr) StochasticNode (reset=nullptr) WhiteNoise (frequency=0.0, min=-1.0, max=1.0, interpolate=true, random_interval=true, reset=nullptr)","title":"Reference library"},{"location":"node/library/#node-reference-library","text":"","title":"Node reference library"},{"location":"node/library/#analysis","text":"CrossCorrelate (input=nullptr, buffer=nullptr, hop_size=0) OnsetDetector (input=0.0, threshold=2.0, min_interval=0.1) VampAnalysis (input=0.0, plugin_id=\"vamp-example-plugins:spectralcentroid:linearcentroid\")","title":"analysis"},{"location":"node/library/#buffer","text":"BeatCutter (buffer=nullptr, segment_count=8, stutter_probability=0.0, stutter_count=1, jump_probability=0.0, duty_cycle=1.0, rate=1.0, segment_rate=1.0) BufferPlayer (buffer=nullptr, rate=1.0, loop=0, start_time=nullptr, end_time=nullptr, clock=nullptr) BufferRecorder (buffer=nullptr, input=0.0, feedback=0.0, loop=false) FeedbackBufferReader (buffer=nullptr) FeedbackBufferWriter (buffer=nullptr, input=0.0, delay_time=0.1) GrainSegments (buffer=nullptr, clock=0, target=0, offsets={}, values={}, durations={}) Granulator (buffer=nullptr, clock=0, pos=0, duration=0.1, pan=0.0, rate=1.0, max_grains=2048) SegmentPlayer (buffer=nullptr, onsets={})","title":"buffer"},{"location":"node/library/#control","text":"MouseX () MouseY () MouseDown (button_index=0)","title":"control"},{"location":"node/library/#envelope","text":"ADSREnvelope (attack=0.1, decay=0.1, sustain=0.5, release=0.1, gate=0) ASREnvelope (attack=0.1, sustain=0.5, release=0.1, curve=1.0, clock=nullptr) Envelope (levels=std::vector<NodeRef> ( ), times=std::vector<NodeRef> ( ), curves=std::vector<NodeRef> ( ), clock=nullptr, loop=false) Line (from=0.0, to=1.0, time=1.0, loop=0, clock=nullptr) EnvelopeRect (sustain=1.0, clock=nullptr)","title":"envelope"},{"location":"node/library/#fft","text":"FFTContinuousPhaseVocoder (input=nullptr, rate=1.0) FFTConvolve (input=nullptr, buffer=nullptr) FFT (input=0.0, fft_size=SIGNALFLOW_DEFAULT_FFT_SIZE, hop_size=SIGNALFLOW_DEFAULT_FFT_HOP_SIZE, window_size=0, do_window=true) FFTNode (fft_size=None, hop_size=None, window_size=None, do_window=None) FFTOpNode (input=nullptr) FFTFindPeaks (input=0, prominence=1, threshold=0.000001, count=SIGNALFLOW_MAX_CHANNELS, interpolate=true) IFFT (input=nullptr, do_window=false) FFTLPF (input=0, frequency=2000) FFTNoiseGate (input=0, threshold=0.5) FFTPhaseVocoder (input=nullptr) FFTTonality (input=0, level=0.5, smoothing=0.9) FFTZeroPhase (input=0)","title":"fft"},{"location":"node/library/#operators","text":"Add (a=0, b=0) AmplitudeToDecibels (a=0) DecibelsToAmplitude (a=0) ChannelArray () ChannelMixer (channels=1, input=0, amplitude_compensation=true) ChannelSelect (input=nullptr, offset=0, maximum=0, step=1) Equal (a=0, b=0) NotEqual (a=0, b=0) GreaterThan (a=0, b=0) GreaterThanOrEqual (a=0, b=0) LessThan (a=0, b=0) LessThanOrEqual (a=0, b=0) Modulo (a=0, b=0) Abs (a=0) If (a=0, value_if_true=0, value_if_false=0) Divide (a=1, b=1) FrequencyToMidiNote (a=0) MidiNoteToFrequency (a=0) Multiply (a=1.0, b=1.0) Pow (a=0, b=0) RoundToScale (a=0) Round (a=0) ScaleLinExp (input=0, a=0, b=1, c=1, d=10) ScaleLinLin (input=0, a=0, b=1, c=1, d=10) Subtract (a=0, b=0) Sum () Tanh (a=0)","title":"operators"},{"location":"node/library/#oscillators","text":"Constant (value=0) Impulse (frequency=1.0) LFO (frequency=1.0, min=0.0, max=1.0) SawLFO (frequency=1.0, min=0.0, max=1.0) SawOscillator (frequency=440) SineLFO (frequency=1.0, min=0.0, max=1.0) SineOscillator (frequency=440) SquareLFO (frequency=1.0, min=0.0, max=1.0, width=0.5) SquareOscillator (frequency=440, width=0.5) TriangleLFO (frequency=1.0, min=0.0, max=1.0) TriangleOscillator (frequency=440) Wavetable (buffer=nullptr, frequency=440, phase=0, sync=0, phase_map=nullptr) Wavetable2D (buffer=nullptr, frequency=440, crossfade=0.0, sync=0)","title":"oscillators"},{"location":"node/library/#processors","text":"Clip (input=nullptr, min=-1.0, max=1.0)","title":"processors"},{"location":"node/library/#processorsdelays","text":"AllpassDelay (input=0.0, delaytime=0.1, feedback=0.5, maxdelaytime=0.5) CombDelay (input=0.0, delaytime=0.1, feedback=0.5, maxdelaytime=0.5) OneTapDelay (input=0.0, delaytime=0.1, maxdelaytime=0.5) Stutter (input=0.0, stutter_time=0.1, stutter_count=1, clock=nullptr, max_stutter_time=1.0)","title":"processors/delays"},{"location":"node/library/#processorsdistortion","text":"Resample (input=0, sample_rate=44100, bit_rate=16) SampleAndHold (input=nullptr, clock=nullptr) Squiz (input=0.0, rate=2.0, chunk_size=1) WaveShaper (input=0.0, buffer=nullptr)","title":"processors/distortion"},{"location":"node/library/#processorsdynamics","text":"Compressor (input=0.0, threshold=0.1, ratio=2, attack_time=0.01, release_time=0.1, sidechain=nullptr) Gate (input=0.0, threshold=0.1) Maximiser (input=0.0, ceiling=0.5, attack_time=1.0, release_time=1.0) RMS (input=0.0)","title":"processors/dynamics"},{"location":"node/library/#processorsfilters","text":"BiquadFilter (input=0.0, filter_type=SIGNALFLOW_FILTER_TYPE_LOW_PASS, cutoff=440, resonance=0.0, peak_gain=0.0) EQ (input=0.0, low_gain=1.0, mid_gain=1.0, high_gain=1.0, low_freq=500, high_freq=5000) MoogVCF (input=0.0, cutoff=200.0, resonance=0.0) SVFilter (input=0.0, filter_type=SIGNALFLOW_FILTER_TYPE_LOW_PASS, cutoff=440, resonance=0.0)","title":"processors/filters"},{"location":"node/library/#processors_1","text":"Fold (input=nullptr, min=-1.0, max=1.0)","title":"processors"},{"location":"node/library/#processorspanning","text":"LinearPanner (channels=2, input=0, pan=0.0) StereoBalance (input=0, balance=0) StereoWidth (input=0, width=1)","title":"processors/panning"},{"location":"node/library/#processors_2","text":"Smooth (input=nullptr, smooth=0.99) WetDry (dry_input=nullptr, wet_input=nullptr, wetness=0.0) Wrap (input=nullptr, min=-1.0, max=1.0)","title":"processors"},{"location":"node/library/#sequencing","text":"ClockDivider (clock=0, factor=1) Counter (clock=0, min=0, max=2147483647) Euclidean (clock=0, sequence_length=0, num_events=0) FlipFlop (clock=0) ImpulseSequence (sequence=std::vector<int> ( ), clock=nullptr) Index (list={}, index=0) Latch (set=0, reset=0) Sequence (sequence=std::vector<float> ( ), clock=nullptr)","title":"sequencing"},{"location":"node/library/#stochastic","text":"Logistic (chaos=3.7, frequency=0.0) PinkNoise (low_cutoff=20.0, high_cutoff=20000.0, reset=nullptr) RandomBrownian (min=-1.0, max=1.0, delta=0.01, clock=nullptr, reset=nullptr) RandomChoice (values=std::vector<float> ( ), clock=nullptr, reset=nullptr) RandomCoin (probability=0.5, clock=nullptr, reset=nullptr) RandomExponentialDist (scale=0.0, clock=nullptr, reset=nullptr) RandomExponential (min=0.001, max=1.0, clock=nullptr, reset=nullptr) RandomGaussian (mean=0.0, sigma=0.0, clock=nullptr, reset=nullptr) RandomImpulseSequence (probability=0.5, length=8, clock=nullptr, explore=nullptr, generate=nullptr, reset=nullptr) RandomImpulse (frequency=1.0, distribution=SIGNALFLOW_EVENT_DISTRIBUTION_UNIFORM, reset=nullptr) RandomUniform (min=0.0, max=1.0, clock=nullptr, reset=nullptr) StochasticNode (reset=nullptr) WhiteNoise (frequency=0.0, min=-1.0, max=1.0, interpolate=true, random_interval=true, reset=nullptr)","title":"stochastic"},{"location":"node/multichannel/","text":"Nodes Multichannel nodes When passing a value to audio-rate input of a Node, the signal is by default monophonic (single-channel). For example, SquareOscillator(440) generates a 1-channel output. It is possible to generate multi-channel output by passing an array of values in the place of a constant. For example, SquareOscillator([440, 880]) generates stereo output with a different frequency in the L and R channels. There is no limit to the number of channels that can be generated by a node. For example, SquareOscillator(list(100 + 50 * n for n in range(100))) will create a node with 100-channel output, each with its own frequency. >>> sq = SquareOscillator ( list ( 100 + 50 * n for n in range ( 100 ))) >>> print ( sq . num_output_channels ) 100 Automatic upmixing There are generally multiple inputs connected to a node, which may themselves have differing number of channels. For example, SquareOscillator(frequency=[100, 200, 300, 400, 500], width=0.7) has a 5-channel input and a 1-channel input. In cases like this, the output of the nodes with fewer channels is upmixed to match the higher-channel inputs. Upmixing here means simply duplicating the output until it reaches the desired number of channels. In the above case, the width input will be upmixed to generate 5 channels, all containing 0.7 . If width were a stereo input with L and R channels, the output would be tiled, alternating between the channels. Each frame of stereo input would then be upmixed to contain [L, R, L, R, L] , where L and R are the samples corresponding to the L and R channels. The key rule is that, for nodes that support upmixing, the output signal has as many channels as the input signal with the highest channel count . This process percolates through the signal chain. For example: SquareOscillator ( frequency = SineLFO ([ 1 , 3 , 5 ], min = 440 , max = 880 ), width = SawLFO ([ 0.5 , 0.6 ], min = 0.25 , max = 0.75 )) The min and max inputs of the frequency LFO would be upmixed to 3 channels each The min and max inputs of the width LFO would be upmixed to 2 channels each Then, the output of the width node would be upmixed from 2 to 3 channels Nodes with fixed input/output channels Some nodes have immutable numbers of input/output channels. For example: StereoPanner has 1 input channel and 2 output channels StereoBalance has 2 input channels and 2 output channels ChannelMixer has an arbitrary number of input channels, but a fixed, user-specified number of output channels Even Nodes that do not have an obvious input (e.g. BufferPlayer ) have input channels, for modulation inputs (for example, modulating the rate of the buffer). When two nodes are connected together with incompatible channel counts (for example, connecting a StereoBalance into a StereoMixer ), an InvalidChannelCountException will be raised. The Channel* node classes There are a number of Node subclasses dedicated to channel handling. ChannelArray : Concatenates the channels of multiple nodes, so that calling ChannelMix with nodes of N and M channels will produce an output of N + M channels. ChannelMixer : Reduces or expands the number of channels by evenly spreading the audio across the output channels. ChannelSelect : Selects sub-channels of the input, either individually or by group. Querying channel subsets with the index operator Single channels of a multi-channel node can be accessed using the index [] operator. For example: square = SquareOscillator ([ 440 , 441 , 442 , 443 ]) output = square [ 0 ] # output now contains a mono output, with a frequency of 440Hz. Slice syntax can be used to query multiple subchannels: square = SquareOscillator ([ 440 , 441 , 442 , 880 ]) output = square [ 0 : 2 ] # now contains a two-channel square wave \u2192 Next: Status and properties","title":"Multichannel"},{"location":"node/multichannel/#nodes","text":"","title":"Nodes"},{"location":"node/multichannel/#multichannel-nodes","text":"When passing a value to audio-rate input of a Node, the signal is by default monophonic (single-channel). For example, SquareOscillator(440) generates a 1-channel output. It is possible to generate multi-channel output by passing an array of values in the place of a constant. For example, SquareOscillator([440, 880]) generates stereo output with a different frequency in the L and R channels. There is no limit to the number of channels that can be generated by a node. For example, SquareOscillator(list(100 + 50 * n for n in range(100))) will create a node with 100-channel output, each with its own frequency. >>> sq = SquareOscillator ( list ( 100 + 50 * n for n in range ( 100 ))) >>> print ( sq . num_output_channels ) 100","title":"Multichannel nodes"},{"location":"node/multichannel/#automatic-upmixing","text":"There are generally multiple inputs connected to a node, which may themselves have differing number of channels. For example, SquareOscillator(frequency=[100, 200, 300, 400, 500], width=0.7) has a 5-channel input and a 1-channel input. In cases like this, the output of the nodes with fewer channels is upmixed to match the higher-channel inputs. Upmixing here means simply duplicating the output until it reaches the desired number of channels. In the above case, the width input will be upmixed to generate 5 channels, all containing 0.7 . If width were a stereo input with L and R channels, the output would be tiled, alternating between the channels. Each frame of stereo input would then be upmixed to contain [L, R, L, R, L] , where L and R are the samples corresponding to the L and R channels. The key rule is that, for nodes that support upmixing, the output signal has as many channels as the input signal with the highest channel count . This process percolates through the signal chain. For example: SquareOscillator ( frequency = SineLFO ([ 1 , 3 , 5 ], min = 440 , max = 880 ), width = SawLFO ([ 0.5 , 0.6 ], min = 0.25 , max = 0.75 )) The min and max inputs of the frequency LFO would be upmixed to 3 channels each The min and max inputs of the width LFO would be upmixed to 2 channels each Then, the output of the width node would be upmixed from 2 to 3 channels","title":"Automatic upmixing"},{"location":"node/multichannel/#nodes-with-fixed-inputoutput-channels","text":"Some nodes have immutable numbers of input/output channels. For example: StereoPanner has 1 input channel and 2 output channels StereoBalance has 2 input channels and 2 output channels ChannelMixer has an arbitrary number of input channels, but a fixed, user-specified number of output channels Even Nodes that do not have an obvious input (e.g. BufferPlayer ) have input channels, for modulation inputs (for example, modulating the rate of the buffer). When two nodes are connected together with incompatible channel counts (for example, connecting a StereoBalance into a StereoMixer ), an InvalidChannelCountException will be raised.","title":"Nodes with fixed input/output channels"},{"location":"node/multichannel/#the-channel-node-classes","text":"There are a number of Node subclasses dedicated to channel handling. ChannelArray : Concatenates the channels of multiple nodes, so that calling ChannelMix with nodes of N and M channels will produce an output of N + M channels. ChannelMixer : Reduces or expands the number of channels by evenly spreading the audio across the output channels. ChannelSelect : Selects sub-channels of the input, either individually or by group.","title":"The Channel* node classes"},{"location":"node/multichannel/#querying-channel-subsets-with-the-index-operator","text":"Single channels of a multi-channel node can be accessed using the index [] operator. For example: square = SquareOscillator ([ 440 , 441 , 442 , 443 ]) output = square [ 0 ] # output now contains a mono output, with a frequency of 440Hz. Slice syntax can be used to query multiple subchannels: square = SquareOscillator ([ 440 , 441 , 442 , 880 ]) output = square [ 0 : 2 ] # now contains a two-channel square wave \u2192 Next: Status and properties","title":"Querying channel subsets with the index operator"},{"location":"node/operators/","text":"Nodes Node operators Arithmetic The output of multiple nodes can be combined using Python's mathematical operators. For example, to sum two sine waves together to create harmonics, use the + operator: output = SineOscillator ( 440 ) + SineOscillator ( 880 ) output . play () To modulate the amplitude of one node with another, use the * operator: sine = SineOscillator ( 440 ) envelope = ASREnvelope ( 0.1 , 1 , 0.1 ) output = sine * envelope You can use constant values in place of Node objects: sine = SineOscillator ( 440 ) attenuated = sine * 0.5 Operators can be chained together in the normal way: # Create an envelope that rises from 0.5 to 1.0 and back to 0.5 env = ( ASREnvelope ( 0.1 , 1 , 0.1 ) * 0.5 ) + 0.5 Behind the scenes, these operators are actually creating composites of Node subclasses. The last example could alternatively be written as: Add ( Multiply ( ASREnvelope ( 0.1 , 1 , 0.1 ), 0.5 ), 0.5 ) Comparison Comparison operators can also be used to compare two Node output values, generating a binary (1/0) output. For example: # Generates an output of 1 when the sinusoid is above 0, and 0 otherwise SineOscillator ( 440 ) > 0 This can then be used as an input to other nodes. The below will generate a half-wave-rectified sine signal (that is, a sine wave with all negative values set to zero). sine = SineOscillator ( 440 ) rectified = sine * ( sine > 0 ) Index of operators Below is a full list of operators supported by SignalFlow. Arithmetic operators Operator Node class + Add - Subtract * Multiply / Divide ** Power % Modulo Comparison operators Operator Node class == Equal != NotEqual < LessThan <= LessThanOrEqual > GreaterThan >= GreaterThanOrEqual \u2192 Next: Multichannel","title":"Operators"},{"location":"node/operators/#nodes","text":"","title":"Nodes"},{"location":"node/operators/#node-operators","text":"","title":"Node operators"},{"location":"node/operators/#arithmetic","text":"The output of multiple nodes can be combined using Python's mathematical operators. For example, to sum two sine waves together to create harmonics, use the + operator: output = SineOscillator ( 440 ) + SineOscillator ( 880 ) output . play () To modulate the amplitude of one node with another, use the * operator: sine = SineOscillator ( 440 ) envelope = ASREnvelope ( 0.1 , 1 , 0.1 ) output = sine * envelope You can use constant values in place of Node objects: sine = SineOscillator ( 440 ) attenuated = sine * 0.5 Operators can be chained together in the normal way: # Create an envelope that rises from 0.5 to 1.0 and back to 0.5 env = ( ASREnvelope ( 0.1 , 1 , 0.1 ) * 0.5 ) + 0.5 Behind the scenes, these operators are actually creating composites of Node subclasses. The last example could alternatively be written as: Add ( Multiply ( ASREnvelope ( 0.1 , 1 , 0.1 ), 0.5 ), 0.5 )","title":"Arithmetic"},{"location":"node/operators/#comparison","text":"Comparison operators can also be used to compare two Node output values, generating a binary (1/0) output. For example: # Generates an output of 1 when the sinusoid is above 0, and 0 otherwise SineOscillator ( 440 ) > 0 This can then be used as an input to other nodes. The below will generate a half-wave-rectified sine signal (that is, a sine wave with all negative values set to zero). sine = SineOscillator ( 440 ) rectified = sine * ( sine > 0 )","title":"Comparison"},{"location":"node/operators/#index-of-operators","text":"Below is a full list of operators supported by SignalFlow.","title":"Index of operators"},{"location":"node/operators/#arithmetic-operators","text":"Operator Node class + Add - Subtract * Multiply / Divide ** Power % Modulo","title":"Arithmetic operators"},{"location":"node/operators/#comparison-operators","text":"Operator Node class == Equal != NotEqual < LessThan <= LessThanOrEqual > GreaterThan >= GreaterThanOrEqual \u2192 Next: Multichannel","title":"Comparison operators"},{"location":"node/playback/","text":"Nodes Playing and stopping a node Starting playback To start a node playing, simply call the play() method: graph = AudioGraph () node = SineOscillator ( 440 ) node . play () This connects the node to the output endpoint of the current global AudioGraph . The next time the graph processes a block of samples, the graph's output node then calls upon the sine oscillator to generate a block. It is important to remember that playing a node means \"connecting it to the graph\". For this reason, it is not possible to play the same node more than once, as it is already connected to the graph. To play multiples of a particular Node type, simply create and play multiple instances. Connecting a Node to another Node's input It is often the case that you want to connect a Node to the input of another Node for playback, rather than simply wiring it to the output of a graph -- for example, to pass an oscillator through a processor. In this case, you do not need to call play() (which means \"connect this node to the graph\"). Instead, it is sufficient to simply connect the Node to the input of another Node that is already playing. For example: # create and begin playback of a variable input summer, passed through a filter sum = Sum () flt = SVFilter ( sum , \"low_pass\" , 200 ) flt . play () Now, let's create an oscillator. Observe that connecting the oscillator to the filter's input begins playback immediately. square = SquareOscillator ( 100 ) sum . add_input ( square ) Stopping playback To stop a node playing: node . stop () This disconnects the node from the output device that it is connected to. \u2192 Next: Inputs","title":"Playback"},{"location":"node/playback/#nodes","text":"","title":"Nodes"},{"location":"node/playback/#playing-and-stopping-a-node","text":"","title":"Playing and stopping a node"},{"location":"node/playback/#starting-playback","text":"To start a node playing, simply call the play() method: graph = AudioGraph () node = SineOscillator ( 440 ) node . play () This connects the node to the output endpoint of the current global AudioGraph . The next time the graph processes a block of samples, the graph's output node then calls upon the sine oscillator to generate a block. It is important to remember that playing a node means \"connecting it to the graph\". For this reason, it is not possible to play the same node more than once, as it is already connected to the graph. To play multiples of a particular Node type, simply create and play multiple instances.","title":"Starting playback"},{"location":"node/playback/#connecting-a-node-to-another-nodes-input","text":"It is often the case that you want to connect a Node to the input of another Node for playback, rather than simply wiring it to the output of a graph -- for example, to pass an oscillator through a processor. In this case, you do not need to call play() (which means \"connect this node to the graph\"). Instead, it is sufficient to simply connect the Node to the input of another Node that is already playing. For example: # create and begin playback of a variable input summer, passed through a filter sum = Sum () flt = SVFilter ( sum , \"low_pass\" , 200 ) flt . play () Now, let's create an oscillator. Observe that connecting the oscillator to the filter's input begins playback immediately. square = SquareOscillator ( 100 ) sum . add_input ( square )","title":"Connecting a Node to another Node's input"},{"location":"node/playback/#stopping-playback","text":"To stop a node playing: node . stop () This disconnects the node from the output device that it is connected to. \u2192 Next: Inputs","title":"Stopping playback"},{"location":"node/properties/","text":"Nodes Node properties A Node has a number of read-only properties which can be used to query its status at a given moment in time. Property Type Description name str Short alphanumeric string that identifies the type of node (for example, asr-envelope ) num_output_channels int The number of output channels that the node generates. num_input_channels int The number of input channels that the node takes. Note that most nodes have matches_input_channels set, meaning that their num_input_channels will be automatically increased according to their inputs. To learn more, see Nodes: Multichannel . matches_input_channels bool Whether the node automatically increases its num_input_channels based on its inputs. To learn more, see Nodes: Multichannel . has_variable_inputs bool Whether the node supports an arbitrary number of audio-rate inputs output_buffer numpy.ndarray Contains the Node's most recent audio output, in float32 samples. The buffer is indexed by channel x frame , so to obtain the 32nd sample in the first channel, query: node.output_buffer[0][31] . inputs dict A dict containing all of the Node 's audio-rate inputs. Note that buffer inputs are not currently included within this dict. state int The Node's current playback state, which can be one of SIGNALFLOW_NODE_STATE_ACTIVE and SIGNALFLOW_NODE_STATE_STOPPED . The STOPPED state only applies to those nodes which have a finite duration (e.g. ASREnvelope , or BufferPlayer with looping disabled) and have reached the end of playback. Nodes continue to have a state of ACTIVE whether or not they are connected to the graph. patch Patch Indicates the Patch that the node is part of, or None if the Node does not belong to a Patch. Monitoring a node's output To monitor the output of a node, call node.poll(num_seconds) , where num_seconds is the interval between messages. This will print the last sample generated by the node to stdout . In the case of multichannel nodes, only the first channel's value is printed. >>> a = Counter(Impulse(1)) >>> a.poll(1) >>> a.play() counter: 0.00000 counter: 1.00000 counter: 2.00000 To stop polling a node, call node.poll(0) . \u2192 Next: Stochastic nodes","title":"Status and properties"},{"location":"node/properties/#nodes","text":"","title":"Nodes"},{"location":"node/properties/#node-properties","text":"A Node has a number of read-only properties which can be used to query its status at a given moment in time. Property Type Description name str Short alphanumeric string that identifies the type of node (for example, asr-envelope ) num_output_channels int The number of output channels that the node generates. num_input_channels int The number of input channels that the node takes. Note that most nodes have matches_input_channels set, meaning that their num_input_channels will be automatically increased according to their inputs. To learn more, see Nodes: Multichannel . matches_input_channels bool Whether the node automatically increases its num_input_channels based on its inputs. To learn more, see Nodes: Multichannel . has_variable_inputs bool Whether the node supports an arbitrary number of audio-rate inputs output_buffer numpy.ndarray Contains the Node's most recent audio output, in float32 samples. The buffer is indexed by channel x frame , so to obtain the 32nd sample in the first channel, query: node.output_buffer[0][31] . inputs dict A dict containing all of the Node 's audio-rate inputs. Note that buffer inputs are not currently included within this dict. state int The Node's current playback state, which can be one of SIGNALFLOW_NODE_STATE_ACTIVE and SIGNALFLOW_NODE_STATE_STOPPED . The STOPPED state only applies to those nodes which have a finite duration (e.g. ASREnvelope , or BufferPlayer with looping disabled) and have reached the end of playback. Nodes continue to have a state of ACTIVE whether or not they are connected to the graph. patch Patch Indicates the Patch that the node is part of, or None if the Node does not belong to a Patch.","title":"Node properties"},{"location":"node/properties/#monitoring-a-nodes-output","text":"To monitor the output of a node, call node.poll(num_seconds) , where num_seconds is the interval between messages. This will print the last sample generated by the node to stdout . In the case of multichannel nodes, only the first channel's value is printed. >>> a = Counter(Impulse(1)) >>> a.poll(1) >>> a.play() counter: 0.00000 counter: 1.00000 counter: 2.00000 To stop polling a node, call node.poll(0) . \u2192 Next: Stochastic nodes","title":"Monitoring a node's output"},{"location":"node/stochastic/","text":"Nodes Chance and stochastic nodes SignalFlow has a number of stochastic nodes, which make use of a pseudo-random number generator (RNG) to produce unpredictable output values. Each object of these StochasticNode subclasses stores its own RNG. By default, the RNG is seeded with a random value, so that each run will generate a different set of outputs. However, to create a repeatable pseudo-random output, the seed of the node's RNG can be set to a known value: >>> r = RandomUniform ( 0 , 1 ) >>> r . process ( 1024 ) >>> r . output_buffer [ 0 ][: 4 ] array ([ 0.48836085 , 0.64326525 , 0.79819506 , 0.8489549 ], dtype = float32 ) >>> r . set_seed ( 123 ) >>> r . process ( 1024 ) >>> r . output_buffer [ 0 ][: 4 ] array ([ 0.7129553 , 0.42847094 , 0.6908848 , 0.7191503 ], dtype = float32 ) >>> r . set_seed ( 123 ) >>> r . process ( 1024 ) >>> r . output_buffer [ 0 ][: 4 ] array ([ 0.7129553 , 0.42847094 , 0.6908848 , 0.7191503 ], dtype = float32 ) Note the identical sequences generated after repeatedly setting the seed to a known value. Warning Calling node.process() is generally not good practice, as it does not recursively process all of the node's inputs (unlike when a node is embedded within an AudioGraph, which correctly handles recursion and cyclical loops). Please use at your peril! \u2192 Next: Node reference library","title":"Stochastic nodes"},{"location":"node/stochastic/#nodes","text":"","title":"Nodes"},{"location":"node/stochastic/#chance-and-stochastic-nodes","text":"SignalFlow has a number of stochastic nodes, which make use of a pseudo-random number generator (RNG) to produce unpredictable output values. Each object of these StochasticNode subclasses stores its own RNG. By default, the RNG is seeded with a random value, so that each run will generate a different set of outputs. However, to create a repeatable pseudo-random output, the seed of the node's RNG can be set to a known value: >>> r = RandomUniform ( 0 , 1 ) >>> r . process ( 1024 ) >>> r . output_buffer [ 0 ][: 4 ] array ([ 0.48836085 , 0.64326525 , 0.79819506 , 0.8489549 ], dtype = float32 ) >>> r . set_seed ( 123 ) >>> r . process ( 1024 ) >>> r . output_buffer [ 0 ][: 4 ] array ([ 0.7129553 , 0.42847094 , 0.6908848 , 0.7191503 ], dtype = float32 ) >>> r . set_seed ( 123 ) >>> r . process ( 1024 ) >>> r . output_buffer [ 0 ][: 4 ] array ([ 0.7129553 , 0.42847094 , 0.6908848 , 0.7191503 ], dtype = float32 ) Note the identical sequences generated after repeatedly setting the seed to a known value. Warning Calling node.process() is generally not good practice, as it does not recursively process all of the node's inputs (unlike when a node is embedded within an AudioGraph, which correctly handles recursion and cyclical loops). Please use at your peril! \u2192 Next: Node reference library","title":"Chance and stochastic nodes"},{"location":"patch/","text":"Patch Warning This documentation is a work-in-progress and may have sections that are missing or incomplete. A Patch represents a connected group of Nodes , analogous to a synthesizer. Defining patches makes it easy to create higher-level structures, which can then be reused and instantiated with a single line of code, in much the same way as a Node. Behind the scenes, the structure of a Patch is encapsulated by a PatchSpec , a template which can be instantiated or serialised to a JSON file for later use. A Patch structure is defined either by declaring a Patch subclass or with a JSON specification file Play and stop a Patch by connecting it to the AudioGraph or the input of another Patch or Node Patch inputs Audio-rate inputs Buffer inputs Trigger node Operators Exporting and importing patches Patch properties Auto-free \u2192 Next: Defining a Patch","title":"Patches"},{"location":"patch/#patch","text":"Warning This documentation is a work-in-progress and may have sections that are missing or incomplete. A Patch represents a connected group of Nodes , analogous to a synthesizer. Defining patches makes it easy to create higher-level structures, which can then be reused and instantiated with a single line of code, in much the same way as a Node. Behind the scenes, the structure of a Patch is encapsulated by a PatchSpec , a template which can be instantiated or serialised to a JSON file for later use. A Patch structure is defined either by declaring a Patch subclass or with a JSON specification file Play and stop a Patch by connecting it to the AudioGraph or the input of another Patch or Node Patch inputs Audio-rate inputs Buffer inputs Trigger node Operators Exporting and importing patches Patch properties Auto-free \u2192 Next: Defining a Patch","title":"Patch"},{"location":"patch/auto-free/","text":"Patch Auto-free and memory management Auto-free.","title":"Auto-free and memory management"},{"location":"patch/auto-free/#patch","text":"","title":"Patch"},{"location":"patch/auto-free/#auto-free-and-memory-management","text":"Auto-free.","title":"Auto-free and memory management"},{"location":"patch/defining/","text":"Patch Defining a Patch A Patch is made up of a connected network of Nodes, together with a set of properties that determine how the Patch can be controlled. There are two general ways to define the structure of a Patch: Create a new class that subclasses Patch . In general, this is the recommended approach for defining new Patches. Create a JSON file that can be loaded as a PatchSpec , which describes the structure of a patch Creating a Patch subclass The quickest and most intuitive way to define a Patch is by subclassing the Patch class itself. Let's look at an example. class Bleep ( Patch ): def __init__ ( self , frequency = 880 , duration = 0.1 ): super () . __init__ () frequency = self . add_input ( \"frequency\" , frequency ) duration = self . add_input ( \"duration\" , duration ) sine = SineOscillator ( frequency ) env = ASREnvelope ( 0.001 , duration , 0.001 ) output = sine * env self . set_output ( output ) self . set_auto_free ( True ) In the above example: At the very start of the __init__ function, super().__init__() must be called to initialise the Patch and its storage. This is vital! Without it, your program will crash. Two audio-rate input parameters are defined. The add_input() method is used to define them as inputs of the Patch , which can then be subsequently modulated. Note that the add_input() method returns a reference to the frequency node, which then acts as a pointer to the input node. self.set_output() is used to define the Patch's output. A Patch can only have one single output. Finally, self.set_auto_free() is used to automatically stop and free the Patch after playback of the envelope is completed. More about auto-free... You can now instantiate a Bleep object in just the same way as you would instantiate and play a Node: b = Bleep(frequency=440, duration=0.2) b.play() If you query graph.status after playback has finished, you should see that the Patch is automatically freed and the number of nodes returns to 0. Creating a PatchSpec from JSON The structure of a Patch is described by a PatchSpec , which can in turn be imported/exported in the JSON text-based data interchange format. For information on loading or saving PatchSpecs as JSON, see Exporting and importing patches . \u2192 Next: Playing and stopping a Patch","title":"Defining a Patch"},{"location":"patch/defining/#patch","text":"","title":"Patch"},{"location":"patch/defining/#defining-a-patch","text":"A Patch is made up of a connected network of Nodes, together with a set of properties that determine how the Patch can be controlled. There are two general ways to define the structure of a Patch: Create a new class that subclasses Patch . In general, this is the recommended approach for defining new Patches. Create a JSON file that can be loaded as a PatchSpec , which describes the structure of a patch","title":"Defining a Patch"},{"location":"patch/defining/#creating-a-patch-subclass","text":"The quickest and most intuitive way to define a Patch is by subclassing the Patch class itself. Let's look at an example. class Bleep ( Patch ): def __init__ ( self , frequency = 880 , duration = 0.1 ): super () . __init__ () frequency = self . add_input ( \"frequency\" , frequency ) duration = self . add_input ( \"duration\" , duration ) sine = SineOscillator ( frequency ) env = ASREnvelope ( 0.001 , duration , 0.001 ) output = sine * env self . set_output ( output ) self . set_auto_free ( True ) In the above example: At the very start of the __init__ function, super().__init__() must be called to initialise the Patch and its storage. This is vital! Without it, your program will crash. Two audio-rate input parameters are defined. The add_input() method is used to define them as inputs of the Patch , which can then be subsequently modulated. Note that the add_input() method returns a reference to the frequency node, which then acts as a pointer to the input node. self.set_output() is used to define the Patch's output. A Patch can only have one single output. Finally, self.set_auto_free() is used to automatically stop and free the Patch after playback of the envelope is completed. More about auto-free... You can now instantiate a Bleep object in just the same way as you would instantiate and play a Node: b = Bleep(frequency=440, duration=0.2) b.play() If you query graph.status after playback has finished, you should see that the Patch is automatically freed and the number of nodes returns to 0.","title":"Creating a Patch subclass"},{"location":"patch/defining/#creating-a-patchspec-from-json","text":"The structure of a Patch is described by a PatchSpec , which can in turn be imported/exported in the JSON text-based data interchange format. For information on loading or saving PatchSpecs as JSON, see Exporting and importing patches . \u2192 Next: Playing and stopping a Patch","title":"Creating a PatchSpec from JSON"},{"location":"patch/exporting/","text":"Patch Exporting and importing patches A Patch can be exported or imported. \u2192 Next: Auto-free and memory management","title":"Exporting and importing patches"},{"location":"patch/exporting/#patch","text":"","title":"Patch"},{"location":"patch/exporting/#exporting-and-importing-patches","text":"A Patch can be exported or imported. \u2192 Next: Auto-free and memory management","title":"Exporting and importing patches"},{"location":"patch/inputs/","text":"Patch Patch inputs Just like a Node , a Patch supports three different classes of input: Audio-rate inputs : Takes the output of another Node or Patch as an input, for continuous modulation of synthesis parameters Trigger inputs : Used to trigger discrete control events \u2014 for example, restarting buffer playback Buffer inputs : Used to pass the contents of an audio buffer to a patch \u2014 for example, as a source of audio samples, or an envelope shape Audio-rate inputs A Patch supports any number of user-defined named inputs, which can be used to modulate the nodes within the patch. Each input must be defined by calling add_input() when the Patch is first defined, with an optional default value. Info Note that Patches do not yet support variable inputs . When a Patch is playing, the value of its inputs can be set using patch.set_input() : class Bloop ( Patch ): def __init__ ( self , frequency = 880 , duration = 0.1 ): super () . __init__ () frequency = self . add_input ( \"frequency\" , frequency ) sine = SineOscillator ( frequency ) self . set_output ( sine ) self . set_auto_free ( True ) bloop = Bloop () bloop . play () ... bloop . set_input ( \"frequency\" , 100 ) Info Note that Patches do not yet support setting inputs with Python properties (e.g. patch.prop_name = 123 ), as is possible with node inputs . Triggers When defining a Patch , it is possible to define which Node should receive trigger() events sent to the Patch. This is done with patch.set_trigger_node() : class Hat ( Patch ): def __init__ ( self , duration = 0.1 ): super () . __init__ () duration = self . add_input ( \"duration\" , duration ) noise = WhiteNoise () env = ASREnvelope ( 0.0001 , 0.0 , duration , curve = 2 ) output = noise * env self . set_trigger_node ( env ) self . set_output ( output ) h = Hat () h . play () ... h . trigger () # triggers a hit, resetting the ASREnvelope to its start point This can be used to create a Patch that stays connected to the AudioGraph and can be retriggered to play a hit. Info Note that Patches only presently support trigger events directed to a single node within the patch, and cannot route triggers to multiple different nodes. Buffer inputs Buffer inputs can be declared at define time by calling self.add_buffer_input() . Similar to add_input , the return value is a placeholder Buffer that can be used wherever you would normally pass a Buffer : class WobblyPlayer ( Patch ): def __init__ ( self , buffer ): super () . __init__ () buffer = self . add_buffer_input ( \"buffer\" , buffer ) rate = SineLFO ( 0.2 , 0.5 , 1.5 ) player = BufferPlayer ( buffer , rate = rate , loop = True ) self . set_output ( player ) buffer = Buffer ( \"examples/audio/stereo-count.wav\" ) player = WobblyPlayer ( buffer ) player . play () The buffer can then be replaced at runtime by calling set_input() : player . set_input ( \"buffer\" , another_buffer ) \u2192 Next: Operators","title":"Inputs"},{"location":"patch/inputs/#patch","text":"","title":"Patch"},{"location":"patch/inputs/#patch-inputs","text":"Just like a Node , a Patch supports three different classes of input: Audio-rate inputs : Takes the output of another Node or Patch as an input, for continuous modulation of synthesis parameters Trigger inputs : Used to trigger discrete control events \u2014 for example, restarting buffer playback Buffer inputs : Used to pass the contents of an audio buffer to a patch \u2014 for example, as a source of audio samples, or an envelope shape","title":"Patch inputs"},{"location":"patch/inputs/#audio-rate-inputs","text":"A Patch supports any number of user-defined named inputs, which can be used to modulate the nodes within the patch. Each input must be defined by calling add_input() when the Patch is first defined, with an optional default value. Info Note that Patches do not yet support variable inputs . When a Patch is playing, the value of its inputs can be set using patch.set_input() : class Bloop ( Patch ): def __init__ ( self , frequency = 880 , duration = 0.1 ): super () . __init__ () frequency = self . add_input ( \"frequency\" , frequency ) sine = SineOscillator ( frequency ) self . set_output ( sine ) self . set_auto_free ( True ) bloop = Bloop () bloop . play () ... bloop . set_input ( \"frequency\" , 100 ) Info Note that Patches do not yet support setting inputs with Python properties (e.g. patch.prop_name = 123 ), as is possible with node inputs .","title":"Audio-rate inputs"},{"location":"patch/inputs/#triggers","text":"When defining a Patch , it is possible to define which Node should receive trigger() events sent to the Patch. This is done with patch.set_trigger_node() : class Hat ( Patch ): def __init__ ( self , duration = 0.1 ): super () . __init__ () duration = self . add_input ( \"duration\" , duration ) noise = WhiteNoise () env = ASREnvelope ( 0.0001 , 0.0 , duration , curve = 2 ) output = noise * env self . set_trigger_node ( env ) self . set_output ( output ) h = Hat () h . play () ... h . trigger () # triggers a hit, resetting the ASREnvelope to its start point This can be used to create a Patch that stays connected to the AudioGraph and can be retriggered to play a hit. Info Note that Patches only presently support trigger events directed to a single node within the patch, and cannot route triggers to multiple different nodes.","title":"Triggers"},{"location":"patch/inputs/#buffer-inputs","text":"Buffer inputs can be declared at define time by calling self.add_buffer_input() . Similar to add_input , the return value is a placeholder Buffer that can be used wherever you would normally pass a Buffer : class WobblyPlayer ( Patch ): def __init__ ( self , buffer ): super () . __init__ () buffer = self . add_buffer_input ( \"buffer\" , buffer ) rate = SineLFO ( 0.2 , 0.5 , 1.5 ) player = BufferPlayer ( buffer , rate = rate , loop = True ) self . set_output ( player ) buffer = Buffer ( \"examples/audio/stereo-count.wav\" ) player = WobblyPlayer ( buffer ) player . play () The buffer can then be replaced at runtime by calling set_input() : player . set_input ( \"buffer\" , another_buffer ) \u2192 Next: Operators","title":"Buffer inputs"},{"location":"patch/operators/","text":"Patch Operators The output of a Patch can be amplified, attenuated, combined, modulated and compared using Python operators, in much the same way as Node : patch = Patch ( patch_spec ) output = patch * 0.5 For a full list of the operators that can be applied to a Patch , see Node operators . \u2192 Next: Patch properties","title":"Operators"},{"location":"patch/operators/#patch","text":"","title":"Patch"},{"location":"patch/operators/#operators","text":"The output of a Patch can be amplified, attenuated, combined, modulated and compared using Python operators, in much the same way as Node : patch = Patch ( patch_spec ) output = patch * 0.5 For a full list of the operators that can be applied to a Patch , see Node operators . \u2192 Next: Patch properties","title":"Operators"},{"location":"patch/playback/","text":"Patch Playing a Patch Once a Patch has been defined or imported, it can be instantiated in two different ways depending on how it was defined: From a Patch subclass From a PatchSpec From a Patch subclass The simplest way to instantiate a Patch is by defining it as a Patch subclass, and then instantiating it in the same way as a Node. class Hat ( Patch ): def __init__ ( self , duration = 0.1 ): super () . __init__ () duration = self . add_input ( \"duration\" , duration ) noise = WhiteNoise () env = ASREnvelope ( 0.0001 , 0.0 , duration , curve = 2 ) output = noise * env self . set_output ( output ) self . set_auto_free ( True ) hat = Hat () hat . play () Once a Patch has finished, its state changes to SIGNALFLOW_PATCH_STATE_STOPPED . Just as with nodes, it is important to remember that playing a patch means \"connecting it to the graph\". For this reason, it is not possible to play the same patch more than once, as it is already connected to the graph. To play multiples of a particular Patch type, simply create and play multiple instances. From a PatchSpec Once a PatchSpec has been created or imported, it can be played by instantiating a Patch with the PatchSpec as an argument: patch = Patch ( patch_spec ) patch . play () Connecting a Patch to another Patch's input A Patch can be connected to the input of another Patch (or Node), in exactly the same way described in Connecting a Node to another Node's input . Once you have got to grips with this paradigm, it becomes simple to build up sophisticated processing graphs by abstracting complex functionality within individual Patch objects, and connecting them to one another. Stopping a Patch As in Node playback , stopping a Patch disconnects it from the AudioGraph. Patches with auto-free are automatically stopped when their lifetimes ends. Patches with an unlimited lifespan must be stopped manually, with: patch . stop () This disconnects the Patch from its output. \u2192 Next: Patch inputs","title":"Playback"},{"location":"patch/playback/#patch","text":"","title":"Patch"},{"location":"patch/playback/#playing-a-patch","text":"Once a Patch has been defined or imported, it can be instantiated in two different ways depending on how it was defined: From a Patch subclass From a PatchSpec","title":"Playing a Patch"},{"location":"patch/playback/#from-a-patch-subclass","text":"The simplest way to instantiate a Patch is by defining it as a Patch subclass, and then instantiating it in the same way as a Node. class Hat ( Patch ): def __init__ ( self , duration = 0.1 ): super () . __init__ () duration = self . add_input ( \"duration\" , duration ) noise = WhiteNoise () env = ASREnvelope ( 0.0001 , 0.0 , duration , curve = 2 ) output = noise * env self . set_output ( output ) self . set_auto_free ( True ) hat = Hat () hat . play () Once a Patch has finished, its state changes to SIGNALFLOW_PATCH_STATE_STOPPED . Just as with nodes, it is important to remember that playing a patch means \"connecting it to the graph\". For this reason, it is not possible to play the same patch more than once, as it is already connected to the graph. To play multiples of a particular Patch type, simply create and play multiple instances.","title":"From a Patch subclass"},{"location":"patch/playback/#from-a-patchspec","text":"Once a PatchSpec has been created or imported, it can be played by instantiating a Patch with the PatchSpec as an argument: patch = Patch ( patch_spec ) patch . play ()","title":"From a PatchSpec"},{"location":"patch/playback/#connecting-a-patch-to-another-patchs-input","text":"A Patch can be connected to the input of another Patch (or Node), in exactly the same way described in Connecting a Node to another Node's input . Once you have got to grips with this paradigm, it becomes simple to build up sophisticated processing graphs by abstracting complex functionality within individual Patch objects, and connecting them to one another.","title":"Connecting a Patch to another Patch's input"},{"location":"patch/playback/#stopping-a-patch","text":"As in Node playback , stopping a Patch disconnects it from the AudioGraph. Patches with auto-free are automatically stopped when their lifetimes ends. Patches with an unlimited lifespan must be stopped manually, with: patch . stop () This disconnects the Patch from its output. \u2192 Next: Patch inputs","title":"Stopping a Patch"},{"location":"patch/properties/","text":"Patch Patch properties Property Type Description nodes list A list of all of the Node objects that make up this Patch inputs dict A dict of key-value pairs corresponding to all of the (audio rate) inputs within the Patch state int The Patch's current playback state, which can be SIGNALFLOW_PATCH_STATE_ACTIVE or SIGNALFLOW_PATCH_STATE_STOPPED . graph AudioGraph A reference to the AudioGraph that the Patch is part of \u2192 Next: Exporting and importing patches","title":"Patch properties"},{"location":"patch/properties/#patch","text":"","title":"Patch"},{"location":"patch/properties/#patch-properties","text":"Property Type Description nodes list A list of all of the Node objects that make up this Patch inputs dict A dict of key-value pairs corresponding to all of the (audio rate) inputs within the Patch state int The Patch's current playback state, which can be SIGNALFLOW_PATCH_STATE_ACTIVE or SIGNALFLOW_PATCH_STATE_STOPPED . graph AudioGraph A reference to the AudioGraph that the Patch is part of \u2192 Next: Exporting and importing patches","title":"Patch properties"}]}